<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI&CV Lab.</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- Google Fonts: Inter for minimalist look -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
  <style>
    html, body { margin: 0; padding: 0; background: #fff; color: #222; font-family: 'Inter', Arial, sans-serif; }
    body { min-height: 100vh; }
    .nav {
      display: flex; justify-content: center; align-items: center; gap: 32px;
      background: #fafafa; border-bottom: 1px solid #ececec;
      font-size: 1.15rem; font-weight: 500; letter-spacing: -0.5px;
      padding: 28px 0 18px 0; position: sticky; top: 0; z-index: 100;
    }
    .nav .tab {
      color: #222; text-decoration: none; padding: 4px 8px; border-radius: 6px; transition: background 0.14s;
      cursor: pointer;
    }
    .nav .tab.active, .nav .tab:hover { background: #efefef; }
    .container { max-width: 900px; margin: 0 auto; padding: 56px 20px 36px 20px; }
    .hidden { display: none; }

    /* Home */
    .lab-title { font-size: 2.5rem; font-weight: 700; margin-bottom: 0.12em; letter-spacing: -1.5px; }
    .lab-slogan { font-size: 1.25rem; font-weight: 300; color: #777; margin-bottom: 2.2em; }
    .lab-description { font-size: 1.1rem; line-height: 1.75; margin-bottom: 2.5em; color: #222; }
    .lab-contact { color: #444; font-size: 1rem; margin-top: 2em; line-height: 1.6; }
    .lab-contact b { color: #222; }
    .section-title { font-size: 1.55rem; font-weight: 600; color: #222; margin-bottom: 1.1em; margin-top: 1.3em; }

    /* News */
    .news-form, .news-list { margin-top: 2em; }
    .news-form input, .news-form textarea {
      width: 100%; font-size: 1rem; padding: 0.7em; margin-bottom: 1em; border-radius: 8px; border: 1px solid #ddd;
      background: #fafbfc; color: #111; font-family: inherit;
    }
    .news-form button {
      padding: 0.6em 1.6em; border: none; border-radius: 8px; background: #333; color: #fff; font-size: 1rem; cursor: pointer;
      font-weight: 500; letter-spacing: 0.1em; transition: background 0.15s;
    }
    .news-form button:hover { background: #111; }
    .news-list { list-style: none; padding: 0; }
    .news-item {
      border-bottom: 1px solid #eee; padding: 1.1em 0; display: flex; justify-content: space-between; align-items: flex-start;
      gap: 20px;
    }
    .news-item-title { font-weight: 600; font-size: 1.06em; color: #181818; }
    .news-item-date { font-size: 0.95em; color: #888; margin-bottom: 0.5em; }
    .news-item-content { color: #444; margin-top: 0.2em; }
    .news-item-remove { border: none; background: none; color: #b90000; font-size: 0.97em; cursor: pointer; margin-left: 10px; }
    
    /* Enhanced News Styles */
    .photo-upload-section {
      margin-bottom: 1em;
    }
    .photo-upload-label {
      display: inline-block;
      padding: 0.5em 1em;
      background: #f0f0f0;
      border: 2px dashed #ccc;
      border-radius: 8px;
      cursor: pointer;
      transition: all 0.2s;
      font-size: 0.9em;
      color: #666;
    }
    .photo-upload-label:hover {
      background: #e8e8e8;
      border-color: #999;
    }
    .photo-preview {
      position: relative;
      display: inline-block;
      margin-top: 0.5em;
    }
    .photo-preview img {
      max-width: 200px;
      max-height: 150px;
      border-radius: 8px;
      border: 2px solid #ddd;
    }
    .remove-photo-btn {
      position: absolute;
      top: -8px;
      right: -8px;
      background: #ff4444;
      color: white;
      border: none;
      border-radius: 50%;
      width: 24px;
      height: 24px;
      cursor: pointer;
      font-size: 12px;
      line-height: 1;
    }
    
    /* News Modal Styles */
    .news-modal {
      display: none;
      position: fixed;
      z-index: 1000;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0,0,0,0.5);
    }
    .news-modal-content {
      background-color: #fff;
      margin: 5% auto;
      padding: 30px;
      border-radius: 12px;
      width: 80%;
      max-width: 700px;
      max-height: 80vh;
      overflow-y: auto;
      position: relative;
    }
    .news-modal-close {
      position: absolute;
      top: 15px;
      right: 20px;
      font-size: 28px;
      font-weight: bold;
      cursor: pointer;
      color: #aaa;
    }
    .news-modal-close:hover {
      color: #000;
    }
    .news-modal-content h2 {
      margin-top: 0;
      color: #222;
      font-size: 1.8em;
    }
    .news-modal-content .news-date {
      color: #888;
      font-size: 0.9em;
      margin-bottom: 1em;
    }
    .news-modal-content .news-content {
      line-height: 1.6;
      color: #444;
      margin-bottom: 1.5em;
    }
    .news-modal-content .news-image {
      width: 100%;
      max-width: 100%;
      border-radius: 8px;
      margin: 1em 0;
    }
    
    /* Enhanced News Item Styles */
    .news-item {
      border-bottom: 1px solid #eee;
      padding: 1.5em 0;
      display: flex;
      justify-content: space-between;
      align-items: flex-start;
      gap: 20px;
      cursor: pointer;
      transition: background-color 0.2s;
    }
    .news-item:hover {
      background-color: #fafafa;
    }
    .news-item-thumbnail {
      width: 80px;
      height: 60px;
      object-fit: cover;
      border-radius: 6px;
      flex-shrink: 0;
    }
    .news-item-content-preview {
      color: #666;
      margin-top: 0.5em;
      display: -webkit-box;
      -webkit-line-clamp: 2;
      -webkit-box-orient: vertical;
      overflow: hidden;
    }
    .read-more-btn {
      background: #333;
      color: white;
      border: none;
      padding: 0.4em 1em;
      border-radius: 6px;
      font-size: 0.85em;
      cursor: pointer;
      margin-top: 0.5em;
      transition: background 0.2s;
    }
    .read-more-btn:hover {
      background: #555;
    }

    /* Projects */
    .projects-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 24px;
      margin-top: 2em;
    }
    .project-card {
      background: #fafbfc;
      border-radius: 12px;
      padding: 1.5em;
      box-shadow: 0 2px 8px rgba(0,0,0,0.08);
      cursor: pointer;
      transition: all 0.3s ease;
      border: 1px solid #eee;
    }
    .project-card:hover {
      transform: translateY(-4px);
      box-shadow: 0 8px 24px rgba(0,0,0,0.12);
    }
    .project-image {
      width: 100%;
      height: 180px;
      object-fit: cover;
      border-radius: 8px;
      margin-bottom: 1em;
    }
    .project-title {
      font-size: 1.2em;
      font-weight: 600;
      color: #222;
      margin-bottom: 0.5em;
    }
    .project-category {
      display: inline-block;
      background: #e3f2fd;
      color: #1976d2;
      padding: 0.3em 0.8em;
      border-radius: 20px;
      font-size: 0.85em;
      font-weight: 500;
      margin-bottom: 0.8em;
    }
    .project-description {
      color: #666;
      line-height: 1.5;
      margin-bottom: 1em;
    }
    .project-meta {
      display: flex;
      justify-content: space-between;
      align-items: center;
      font-size: 0.9em;
      color: #888;
    }
    .project-duration {
      font-weight: 500;
    }
    .project-status {
      padding: 0.2em 0.6em;
      border-radius: 12px;
      font-size: 0.8em;
      font-weight: 500;
    }
    .status-ongoing {
      background: #fff3e0;
      color: #f57c00;
    }
    .status-completed {
      background: #e8f5e8;
      color: #388e3c;
    }
    .status-upcoming {
      background: #f3e5f5;
      color: #7b1fa2;
    }
    
    /* Project Modal Styles */
    .project-modal {
      display: none;
      position: fixed;
      z-index: 1000;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0,0,0,0.5);
    }
    .project-modal-content {
      background-color: #fff;
      margin: 3% auto;
      padding: 30px;
      border-radius: 12px;
      width: 85%;
      max-width: 800px;
      max-height: 90vh;
      overflow-y: auto;
      position: relative;
    }
    .project-modal-close {
      position: absolute;
      top: 15px;
      right: 20px;
      font-size: 28px;
      font-weight: bold;
      cursor: pointer;
      color: #aaa;
    }
    .project-modal-close:hover {
      color: #000;
    }
    .project-modal-content h2 {
      margin-top: 0;
      color: #222;
      font-size: 1.8em;
    }
    .project-modal-content .project-category {
      display: inline-block;
      background: #e3f2fd;
      color: #1976d2;
      padding: 0.3em 0.8em;
      border-radius: 20px;
      font-size: 0.85em;
      font-weight: 500;
      margin-bottom: 1em;
    }
    .project-modal-content .project-duration {
      color: #888;
      font-size: 0.9em;
      margin-bottom: 1em;
    }
    .project-modal-content .project-description {
      line-height: 1.6;
      color: #444;
      margin-bottom: 1.5em;
    }
    .project-modal-content .project-image {
      width: 100%;
      max-width: 100%;
      height: auto;
      border-radius: 8px;
      margin: 1em 0;
      object-fit: contain;
    }
    .project-modal-content .project-objectives {
      margin: 1.5em 0;
    }
    .project-modal-content .project-objectives h3 {
      color: #333;
      font-size: 1.2em;
      margin-bottom: 0.8em;
      font-weight: 600;
    }
    .project-modal-content .project-objectives ul {
      margin: 0;
      padding-left: 1.5em;
    }
    .project-modal-content .project-objectives li {
      margin-bottom: 0.8em;
      color: #555;
      line-height: 1.5;
    }
    .project-modal-content .project-technologies {
      margin: 1.5em 0;
    }
    .project-modal-content .project-technologies h3 {
      color: #333;
      font-size: 1.2em;
      margin-bottom: 0.8em;
      font-weight: 600;
    }
    .project-modal-content .project-technologies ul {
      margin: 0;
      padding-left: 1.5em;
    }
    .project-modal-content .project-technologies li {
      margin-bottom: 0.8em;
      color: #555;
      line-height: 1.5;
    }
    .project-modal-content .project-team {
      margin: 1.5em 0;
    }
    .project-modal-content .project-team h3 {
      color: #333;
      font-size: 1.2em;
      margin-bottom: 0.8em;
      font-weight: 600;
    }
    .project-modal-content .project-team ul {
      margin: 0;
      padding-left: 1.5em;
    }
    .project-modal-content .project-team li {
      margin-bottom: 0.8em;
      color: #555;
      line-height: 1.5;
    }
    .project-modal-content .project-status {
      display: inline-block;
      padding: 0.2em 0.6em;
      border-radius: 12px;
      font-size: 0.8em;
      font-weight: 500;
      margin-top: 1em;
    }
    .project-modal-content .status-ongoing {
      background: #fff3e0;
      color: #f57c00;
    }
    .project-modal-content .status-completed {
      background: #e8f5e8;
      color: #388e3c;
    }
    .project-modal-content .status-upcoming {
      background: #f3e5f5;
      color: #7b1fa2;
    }

    /* Publications */
    .pub-list { list-style: none; padding: 0; margin: 0; }
    .pub-item { padding: 1.1em 0; border-bottom: 1px solid #efefef; }
    .pub-title { font-weight: 600; color: #232323; font-size: 1.08em; }
    .pub-authors { font-size: 0.97em; color: #777; margin-top: 0.2em; }
    .pub-venue { font-size: 0.96em; color: #555; }
    .pub-link { color: #1a50b9; text-decoration: none; font-size: 0.98em; margin-left: 7px; }

    /* Members */
    .professor, .current-members { display: flex; flex-wrap: wrap; gap: 28px; margin-bottom: 2.2em; }
    .member-card { min-width: 200px; max-width: 230px; background: #fafbfc; border-radius: 18px; padding: 1.2em 1em 1.1em 1em; box-shadow: 0 1px 10px rgba(0,0,0,0.05); display: flex; flex-direction: column; align-items: center; transition: box-shadow 0.13s; }
    .member-card:hover {
      transform: translateY(-4px);
      box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }
    .member-card img {
      width: 78px; height: 78px; border-radius: 50%; object-fit: cover; margin-bottom: 0.7em; border: 2px solid #eee;
    }
    .member-name { font-size: 1.08em; font-weight: 600; margin-bottom: 0.23em; color: #1a1a1a; }
    .member-role { font-size: 0.97em; color: #888; margin-bottom: 0.2em; }
    .member-email { font-size: 0.95em; color: #555; margin-bottom: 0.1em; }
    .alumni-list { list-style: none; padding: 0 0 0 8px; color: #555; font-size: 1em; }
    
    /* Member Modal Styles */
    .member-modal {
      display: none;
      position: fixed;
      z-index: 1000;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0,0,0,0.5);
    }
    .member-modal-content {
      background-color: #fff;
      margin: 3% auto;
      padding: 30px;
      border-radius: 12px;
      width: 85%;
      max-width: 800px;
      max-height: 90vh;
      overflow-y: auto;
      position: relative;
    }
    .member-modal-close {
      position: absolute;
      top: 15px;
      right: 20px;
      font-size: 28px;
      font-weight: bold;
      cursor: pointer;
      color: #aaa;
    }
    .member-modal-close:hover {
      color: #000;
    }
    .member-modal-content h2 {
      margin-top: 0;
      color: #222;
      font-size: 1.8em;
    }
    .member-modal-content .member-role {
      color: #1976d2;
      font-size: 1.1em;
      font-weight: 500;
      margin-bottom: 1em;
    }
    .member-modal-content .member-email {
      color: #666;
      font-size: 0.95em;
      margin-bottom: 1.5em;
    }
    .member-modal-content .member-image {
      width: 120px;
      height: 120px;
      border-radius: 50%;
      object-fit: cover;
      margin: 1em 0;
      border: 3px solid #eee;
    }
    .member-modal-content .member-details {
      margin: 1.5em 0;
    }
    .member-modal-content .member-details h3 {
      color: #333;
      font-size: 1.2em;
      margin-bottom: 0.8em;
      font-weight: 600;
    }
    .member-modal-content .member-details ul {
      margin: 0;
      padding-left: 1.5em;
    }
    .member-modal-content .member-details li {
      margin-bottom: 0.8em;
      color: #555;
      line-height: 1.5;
    }
    .member-modal-content .member-details .admission-date {
      font-weight: 500;
      color: #1976d2;
    }
    .member-modal-content .member-details .awards {
      color: #d32f2f;
      font-weight: 500;
    }

    /* Responsive */
    @media (max-width: 700px) {
      .container { padding: 32px 2vw 20px 2vw; }
      .professor, .current-members { flex-direction: column; gap: 16px; }
      .nav { gap: 17px; font-size: 1rem; }
    }

    /* Member Modal Content Styling */
    .member-modal-content .member-section {
      margin-bottom: 1.5em;
    }
    .member-modal-content .member-section-title {
      font-size: 1.08em;
      font-weight: 600;
      margin-bottom: 0.3em;
      color: #222;
      border-bottom: 1px solid #eee;
      padding-bottom: 0.2em;
    }
    .member-modal-content .member-section-content {
      font-size: 1em;
      color: #444;
      margin-left: 0.2em;
      margin-top: 0.2em;
    }

    /* Add to CSS */
    .lab-description-en, .lab-description-kr {
      background: #f7fafd;
      border-left: 5px solid #1976d2;
      border-radius: 12px;
      padding: 1.3em 1.5em 1.3em 2.2em;
      margin-bottom: 1.5em;
      font-size: 1.13em;
      line-height: 1.85;
      color: #223;
      box-shadow: 0 2px 8px rgba(25, 118, 210, 0.04);
      position: relative;
    }
    .lab-description-en::before {
      content: '';
      position: absolute;
      left: 0.7em;
      top: 1.1em;
      font-size: 1.3em;
    }
    .lab-description-kr::before {
      content: '';
      position: absolute;
      left: 0.7em;
      top: 1.1em;
      font-size: 1.3em;
    }

    .members-section {
      margin-bottom: 3rem;
    }

    .members-section h2 {
      color: #333;
      margin-bottom: 1.5rem;
      font-size: 1.8rem;
      /* border-bottom: 2px solid #007bff; */
      padding-bottom: 0.5rem;
    }

    .members-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 2rem;
      margin-bottom: 2rem;
    }
  </style>
</head>
<body>
  <nav class="nav">
	<img src="images/Logo.png" alt="Lab Logo" class="nav-logo", style="width:100px; height:auto;">
    <span class="tab active" data-tab="home">Home</span>
    <span class="tab" data-tab="news">News</span>
    <span class="tab" data-tab="projects">Projects</span>
    <span class="tab" data-tab="publications">Publications</span>
    <span class="tab" data-tab="members">Members</span>
  </nav>

  <div class="container" id="home-tab">
	<img src="images/단체사진.jpg" alt="Lab Main Visual" class="home-main-image", style="width:100%; height:440px; object-fit:cover; border-radius:18px;">
    <div class="lab-title">Artificial Intelligence & Computer Vision Lab.</div>
    <div class="lab-slogan">Konkuk University, Korea</div>
    <div class="lab-description-en">
      At the AI & Computer Vision Lab (AI&CV Lab) at Konkuk University, we explore how artificial intelligence can understand and interact with the world across multiple modalities (speech, vision, and biosignals) to solve real-world problems.<br>
      <br>
      Led by Professor Eun Yi Kim, our lab brings together passionate researchers working at the intersection of deep learning, multimodal fusion, and human-centered AI. We focus on creating robust, interpretable, and scalable AI systems that thrive in challenging environments—where data may be noisy, missing, or ambiguous.<br>
      <br>
      From recognizing emotions in spontaneous speech, to understanding human behavior through videos and brain signals, our work pushes the boundaries of how machines can sense, learn, and respond with empathy and precision.<br>
    </div>
    <div style="height: 0.5em;"></div>
    <div class="lab-description-kr">
      건국대학교 AI & Computer Vision Lab (AI&CV Lab)은 음성, 영상, 생체신호(EEG, ECG 등)와 같은 다양한 모달리티를 이해하고 통합하는 인공지능 기술을 통해 현실의 복잡한 문제를 해결하는 것을 목표로 합니다.<br>
      <br>
      김은이 교수님의 지도로 운영되는 본 연구실은 딥러닝, 멀티모달 융합, 사람 중심 AI의 교차점에서 혁신적인 연구를 수행하고 있으며, 불완전하고 노이즈가 많은 환경에서도 견고하고 해석 가능한 AI 시스템을 만드는 데 집중하고 있습니다.<br>
      <br>
      자연스러운 대화 속에서 감정을 인식하고, 일상 영상과 뇌파 신호를 통해 인간의 행동을 이해하는 연구를 통해, 인간을 더 잘 이해하는 AI를 만들어가고 있습니다.<br>
      </div>
    <div class="lab-contact">
	  Department of Computer Science and Engineering, Konkuk University, Seoul, Korea<br>
      <b>Location:</b> Room 1005, New Engineering Bldg, 120 Neungdong-ro, Gwangjin-gu, Seoul 05029, Korea<br>
      <b>Email:</b> eykim@konkuk.ac.kr<br>
      <b>Contact:</b> +82-2-450-4135
    </div>
  </div>

  <div class="container hidden" id="news-tab">
    <div class="section-title" style="display:flex;align-items:center;gap:10px;">
      News
    </div>
    <form class="news-form" id="newsForm" style="display:none;">
      <input type="text" id="newsTitle" placeholder="News title" required>
      <textarea id="newsContent" placeholder="News content..." rows="4" required></textarea>
             <div class="photo-upload-section">
         <label for="newsPhoto" class="photo-upload-label">
           <span>📷 Add Photo (Optional)</span>
           <input type="file" id="newsPhoto" accept="image/*" style="display:none;">
         </label>
         <div id="photoPreview" class="photo-preview" style="display:none;">
           <img id="previewImage" alt="Preview">
           <button type="button" id="removePhoto" class="remove-photo-btn">✕</button>
         </div>
         <div style="font-size: 0.8em; color: #666; margin-top: 0.5em;">
           Note: Photo upload to Google Sheets is not supported. Please add image URLs manually in the spreadsheet.
         </div>
       </div>
      <button type="submit">Add News</button>
    </form>
    <ul class="news-list" id="newsList"></ul>
    
    <!-- News Detail Modal -->
    <div id="newsModal" class="news-modal">
      <div class="news-modal-content">
        <span class="news-modal-close">&times;</span>
        <div id="newsModalContent">
          <!-- Modal content will be populated dynamically -->
        </div>
      </div>
    </div>
  </div>

  <div class="container hidden" id="projects-tab">
    <div class="section-title">Research Projects</div>
    <div class="projects-grid" id="projectsGrid">
      <!-- Project blocks will be populated dynamically -->
    </div>
    
    <!-- Project Detail Modal -->
    <div id="projectModal" class="project-modal">
      <div class="project-modal-content">
        <span class="project-modal-close">&times;</span>
        <div id="projectModalContent">
          <!-- Modal content will be populated dynamically -->
        </div>
      </div>
    </div>
  </div>

  <div class="container hidden" id="publications-tab">
    <div class="section-title">Publications</div>
    <ul class="pub-list" id="pubList">
      <!-- 예시 논문 (최신순) -->
    </ul>
  </div>

  <div class="container hidden" id="members-tab">
    <div class="section-title">Professor</div>
    <div class="professor">
      <div class="member-card">
        <img src="images/empty.png" alt="eunyikim">
        <div class="member-name">Eun Yi Kim</div>
        <div class="member-role">Professor</div>
        <div class="member-email">eykim@konkuk.ac.kr</div>
      </div>
    </div>

    <!-- Senior Members Section -->
    <div class="members-section">
      <h2>Senior Members</h2>
              <div class="members-grid">
          <div class="member-card">
            <img src="images/김룡빈.jpg" alt="longbinjin">
            <div class="member-name">Longbin Jin</div>
            <div class="member-role">Ph.D. Graduate</div>
            <div class="member-email">jinlongbin@konkuk.ac.kr, lbjin@voinosis.com</div>
          </div>
        </div>
    </div>

    <!-- Current Members Section -->
    <div class="members-section">
      <h2>Current Members</h2>
      <div class="members-grid">
        <div class="member-card">
          <img src="images/오예림.jpg" alt="yealimoh">
          <div class="member-name">Yealim Oh</div>
          <div class="member-role">Master Student</div>
          <div class="member-email">dodoh0125@konkuk.ac.kr</div>
        </div>
        <div class="member-card">
          <img src="images/전효진.jpg" alt="hyojinjon">
          <div class="member-name">Hyo Jin Jon</div>
          <div class="member-role">Master Student</div>
          <div class="member-email">hyojin2011@konkuk.ac.kr</div>
        </div>
        <div class="member-card">
          <img src="images/정현택.jpg" alt="hyuntaekjung">
          <div class="member-name">Hyuntaek Jung</div>
          <div class="member-role">Master Student</div>
          <div class="member-email">busan199@konkuk.ac.kr</div>
        </div>
        <div class="member-card">
          <img src="images/김현서.jpg" alt="hyunseokim">
          <div class="member-name">Hyunseo Kim</div>
          <div class="member-role">Master Student</div>
          <div class="member-email">hs11015@konkuk.ac.kr</div>
        </div>
        <div class="member-card">
          <img src="images/최희재.jpg" alt="heejaechoi">
          <div class="member-name">Heejae Choi</div>
          <div class="member-role">Master Student</div>
          <div class="member-email">qkw1205@konkuk.ac.kr</div>
        </div>
        <div class="member-card">
          <img src="images/함신우.jpg" alt="shinwooham">
          <div class="member-name">Shinwoo Ham</div>
          <div class="member-role">Master Student</div>
          <div class="member-email">gka0656@konkuk.ac.kr</div>
        </div>
        <div class="member-card">
          <img src="images/민동훈.jpg" alt="donghunmin">
          <div class="member-name">Donghun Min</div>
          <div class="member-role">Master Student</div>
          <div class="member-email">mindonghun@konkuk.ac.kr</div>
        </div>
        <div class="member-card">
          <img src="images/전준일.jpg" alt="juniljeon">
          <div class="member-name">Junil Jeon</div>
          <div class="member-role">Master Student</div>
          <div class="member-email">jeonjunil@konkuk.ac.kr</div>
        </div>
        <div class="member-card">
          <img src="images/empty.png" alt="myeonghunjung">
          <div class="member-name">Myeonghun Jung</div>
          <div class="member-role">Undergraduate Student</div>
          <div class="member-email">jmfc02@naver.com</div>
        </div>
      </div>
    </div>
    <div class="section-title">Alumni</div>
    <ul class="alumni-list">
	  <li>Longbin Jin</li>
	  <li>Oug Hyen Cheong</li>
      <li>Jaeyoung Chang</li>
      <li>Chenghuan Zheng</li>
      <li>Jinxi Li</li>
      <li>Yaohui Yu</li>
      <li>Keumhee Kang</li>
      <li>MyeongJin Lee</li>
      <li>Chanhee Yoon</li>
      <li>Jinyoung Ahn</li>
      <li>Yeounggwang Ji</li>
      <li>Umid Akhmedjanov</li>
      <li>Jihye Hwang</li>
      <li>Eunjeong Ko</li>
      <li>Byung-geun Kim</li>
      <li>Yong-rae Kim</li>
      <li>Jin-Sun Ju</li>
      <li>Na-yeon Kim</li>
      <li>Yun-hee Shin</li>
      <li>Kun-il Lee</li>
      <li>Ki-young Jeong</li>
      <li>Kyung-tae Kim</li>
    </ul>
    
    <!-- Member Detail Modal -->
    <div id="memberModal" class="member-modal">
      <div class="member-modal-content">
        <span class="member-modal-close">&times;</span>
        <div id="memberModalContent">
          <!-- Modal content will be populated dynamically -->
        </div>
      </div>
    </div>
  </div>

  <script>
    // 탭 기능
    const tabs = document.querySelectorAll('.tab');
    const containers = {
      'home': document.getElementById('home-tab'),
      'news': document.getElementById('news-tab'),
      'projects': document.getElementById('projects-tab'),
      'publications': document.getElementById('publications-tab'),
      'members': document.getElementById('members-tab'),
    };
    tabs.forEach(tab => tab.addEventListener('click', () => {
      tabs.forEach(t => t.classList.remove('active'));
      tab.classList.add('active');
      Object.values(containers).forEach(c => c.classList.add('hidden'));
      containers[tab.dataset.tab].classList.remove('hidden');
    }));

    // ----- News: 관리자 기능 -----
	const NEWS_API_URL = "https://script.google.com/macros/s/AKfycbxdfLycEaXnm91mGMyWQ6-F2iwXO4l-WqPwTNGTFLAyppgnrPxfDc4oBD3w1yUIMuvbBA/exec";
    // Admin authentication (password is hashed for security)
    const ADMIN_PASS_HASH = "DC90C09E98F7B5C3D97F52FE1379689A978FE0EB71CF2E34E91F01B6688D208E";
    let isAdmin = false;
    const adminLoginBtn = document.getElementById('adminLoginBtn');
    const adminLogoutBtn = document.getElementById('adminLogoutBtn');
    const newsForm = document.getElementById('newsForm');
    const newsList = document.getElementById('newsList');
    let cachedNews = [];

    function updateAdminUI() {
		if (isAdmin) {
			newsForm.style.display = "";
			Array.from(document.getElementsByClassName('news-item-remove')).forEach(btn => btn.style.display = '');
			adminLoginBtn.style.display = "none";
			adminLogoutBtn.style.display = "";
		} else {
			newsForm.style.display = "none";
			Array.from(document.getElementsByClassName('news-item-remove')).forEach(btn => btn.style.display = 'none');
			adminLoginBtn.style.display = "";
			adminLogoutBtn.style.display = "none";
		}
	}

    // Secure password verification function
    async function verifyPassword(inputPassword) {
      const encoder = new TextEncoder();
      const data = encoder.encode(inputPassword);
      const hashBuffer = await crypto.subtle.digest('SHA-256', data);
      const hashArray = Array.from(new Uint8Array(hashBuffer));
      const hashedInput = hashArray.map(b => b.toString(16).padStart(2, '0')).join('').toUpperCase();
      return hashedInput === ADMIN_PASS_HASH;
    }

    adminLoginBtn.onclick = async function() {
      const pass = prompt("관리자 비밀번호를 입력하세요:");
      if (pass !== null) {
        const isValid = await verifyPassword(pass);
        if (isValid) {
          isAdmin = true;
          updateAdminUI();
          console.log("Admin login successful");
        } else {
          alert("비밀번호가 틀렸습니다.");
          console.log("Admin login failed");
        }
      }
    };
    adminLogoutBtn.onclick = function() {
      isAdmin = false;
      updateAdminUI();
    };

    // News (편집 권한 연동)
    // function loadNews() {
    //   const news = JSON.parse(localStorage.getItem('milab_news') || '[]');
    //   newsList.innerHTML = '';
    //   news.forEach((item, idx) => {
    //     const li = document.createElement('li');
    //     li.className = 'news-item';
    //     li.innerHTML = `
    //       <div style="flex:1;">
    //         <div class="news-item-title">${item.title}</div>
    //         <div class="news-item-date">${item.date}</div>
    //         <div class="news-item-content">${item.content}</div>
    //       </div>
    //       <button class="news-item-remove" title="Delete" onclick="removeNews(${idx})" style="display:none;">✕</button>
    //     `;
    //     newsList.appendChild(li);
    //   });
    //   updateAdminUI();
    // }
    // function saveNews(news) {
    //   localStorage.setItem('milab_news', JSON.stringify(news));
    //   loadNews();
    // }
    // newsForm.addEventListener('submit', function(e){
    //   e.preventDefault();
    //   const title = document.getElementById('newsTitle').value.trim();
    //   const content = document.getElementById('newsContent').value.trim();
    //   if (!title || !content) return;
    //   const news = JSON.parse(localStorage.getItem('milab_news') || '[]');
    //   const date = new Date().toLocaleDateString('en-CA', {year:'numeric',month:'2-digit',day:'2-digit'});
    //   news.unshift({title, content, date});
    //   saveNews(news);
    //   this.reset();
    // });
    // window.removeNews = function(idx) {
    //   if (!isAdmin) return;
    //   const news = JSON.parse(localStorage.getItem('milab_news') || '[]');
    //   news.splice(idx, 1);
    //   saveNews(news);
    // }
    // 최초 로드
	// 뉴스 불러오기(조회)
	function loadNews() {
	console.log("Loading news from:", NEWS_API_URL);
	fetch(NEWS_API_URL)
		.then(res => {
			console.log("Load news response status:", res.status);
			if (!res.ok) {
				throw new Error(`HTTP error! status: ${res.status}`);
			}
			return res.json();
		})
		.then(news => {
			console.log("Loaded news:", news);
			// Debug: Check each news item for image data
			news.forEach((item, index) => {
				console.log(`News ${index}:`, {
					title: item.title,
					content: item.content,
					date: item.date,
					image: item.image,
					hasImage: item.image && item.image.trim() !== ''
				});
			});
			cachedNews = news; // cache the news
		newsList.innerHTML = '';
		news.forEach((item, idx) => {
			const li = document.createElement('li');
			li.className = 'news-item';
			
			// Create thumbnail if image exists
			const thumbnail = item.image ? `<img src="${item.image}" alt="News thumbnail" class="news-item-thumbnail">` : '';
			
			// Format date from ISO string to "YYYY-MM-DD HH:mm" format
			const formatDate = (dateString) => {
				const date = new Date(dateString);
				const year = date.getFullYear();
				const month = String(date.getMonth() + 1).padStart(2, '0');
				const day = String(date.getDate()).padStart(2, '0');
				const hours = String(date.getHours()).padStart(2, '0');
				const minutes = String(date.getMinutes()).padStart(2, '0');
				return `${year}-${month}-${day} ${hours}:${minutes}`;
			};
			
			// Create content preview (first 100 characters)
			const contentPreview = item.content.length > 100 ? 
				item.content.substring(0, 100) + '...' : item.content;
			
			li.innerHTML = `
			<div style="flex:1;">
				<div class="news-item-title">${item.title}</div>
				<div class="news-item-date">${formatDate(item.date)}</div>
				<div class="news-item-content-preview">${contentPreview}</div>
				<button class="read-more-btn" onclick="showNewsDetail(${idx})">Read More</button>
			</div>
			${thumbnail}
			`;
			
			// Store full news data for modal
			li.dataset.newsIndex = idx;
			newsList.appendChild(li);
		});
		updateAdminUI();
		})
		.catch(error => {
			console.error("Error loading news:", error);
			console.error("Error details:", error.message);
			alert("Error loading news. Please check your Google Apps Script setup.");
		});
	}

	// Photo upload functionality
	const newsPhotoInput = document.getElementById('newsPhoto');
	const photoPreview = document.getElementById('photoPreview');
	const previewImage = document.getElementById('previewImage');
	const removePhotoBtn = document.getElementById('removePhoto');
	let selectedPhoto = null;

	newsPhotoInput.addEventListener('change', function(e) {
		const file = e.target.files[0];
		if (file) {
			const reader = new FileReader();
			reader.onload = function(e) {
				previewImage.src = e.target.result;
				photoPreview.style.display = 'block';
				selectedPhoto = file;
			};
			reader.readAsDataURL(file);
		}
	});

	removePhotoBtn.addEventListener('click', function() {
		newsPhotoInput.value = '';
		photoPreview.style.display = 'none';
		selectedPhoto = null;
	});

	// Modal functionality
	const newsModal = document.getElementById('newsModal');
	const newsModalContent = document.getElementById('newsModalContent');
	const newsModalClose = document.querySelector('.news-modal-close');

	// Close modal when clicking X or outside
	newsModalClose.onclick = function() {
		newsModal.style.display = "none";
	}

	window.onclick = function(event) {
		if (event.target == newsModal) {
			newsModal.style.display = "none";
		}
	}

	// Show news detail in modal
	window.showNewsDetail = function(index) {
		const item = cachedNews[index];
		if (item) {
			// Format date for modal
			const formatDate = (dateString) => {
				const date = new Date(dateString);
				const year = date.getFullYear();
				const month = String(date.getMonth() + 1).padStart(2, '0');
				const day = String(date.getDate()).padStart(2, '0');
				const hours = String(date.getHours()).padStart(2, '0');
				const minutes = String(date.getMinutes()).padStart(2, '0');
				return `${year}-${month}-${day} ${hours}:${minutes}`;
			};
			
			// Debug: Log the item to see what data we have
			console.log("News item for modal:", item);
			console.log("Image URL:", item.image);
			
			// Check if image exists and is not empty
			const hasImage = item.image && item.image.trim() !== '';
			const imageHtml = hasImage ? `<img src="${item.image}" alt="News image" class="news-image" onerror="this.style.display='none'">` : '';
			
			newsModalContent.innerHTML = `
				<h2>${item.title}</h2>
				<div class="news-date">${formatDate(item.date)}</div>
				${imageHtml}
				<div class="news-content">${item.content}</div>
			`;
			newsModal.style.display = "block";
		}
	}

	// 뉴스 등록(추가)
	newsForm.addEventListener('submit', function(e){
	e.preventDefault();
	
	// Check if admin is logged in
	if (!isAdmin) {
		alert("Please log in as admin first.");
		return;
	}
	
	const title = document.getElementById('newsTitle').value.trim();
	const content = document.getElementById('newsContent').value.trim();
	if (!title || !content) {
		alert("Please fill in both title and content");
		return;
	}
	
	const date = new Date().toLocaleDateString('en-CA', {year:'numeric',month:'2-digit',day:'2-digit'});
	
	// Create URL-encoded data for Google Apps Script
	const data = new URLSearchParams();
	data.append('title', title);
	data.append('content', content);
	data.append('date', date);
	
	// For now, we'll skip image upload to Google Sheets
	// as it requires more complex handling
	if (selectedPhoto) {
		console.log("Image upload not supported for Google Sheets yet");
		alert("Image upload is not supported with Google Sheets. Please add images manually by uploading to a cloud service and adding the URL to the spreadsheet.");
	}
	
	console.log("Submitting news:", { title, content, date });
	console.log("API URL:", NEWS_API_URL);
	console.log("Admin status:", isAdmin);
	
	fetch(NEWS_API_URL, {
		method: "POST",
		body: data,
		headers: {
			'Content-Type': 'application/x-www-form-urlencoded',
		}
	})
	.then(response => {
		console.log("Response status:", response.status);
		console.log("Response headers:", response.headers);
		if (!response.ok) {
			throw new Error(`HTTP error! status: ${response.status}`);
		}
		return response.text(); // Use text() instead of json() to see raw response
	})
	.then(data => {
		console.log("Raw response:", data);
		try {
			const jsonData = JSON.parse(data);
			console.log("News submitted successfully:", jsonData);
			loadNews();
			this.reset();
			photoPreview.style.display = 'none';
			selectedPhoto = null;
			alert("News added successfully!");
		} catch (e) {
			console.log("Response is not JSON:", data);
			// Even if response is not JSON, consider it successful if we got a response
			loadNews();
			this.reset();
			photoPreview.style.display = 'none';
			selectedPhoto = null;
			alert("News added successfully!");
		}
	})
	.catch(error => {
		console.error("Error submitting news:", error);
		console.error("Error details:", error.message);
		alert("Error adding news. Please check your Google Apps Script setup and try again.");
	});
	});
    loadNews();

    // ----- Projects: 예시 데이터 -----
    const projectsData = [
      {
        id: 7,
        title: "Speech Emotion Recognition using Deep Learning",
        category: "Signal Processing & NLP",
        description: "This project focuses on developing robust speech-based emotion recognition systems tailored for real-world conditions. By leveraging hierarchical structures in speech and advanced deep learning models, we aim to improve generalizability across speakers, recording environments, and emotional ambiguities. Our approach integrates acoustic and textual modalities and explores novel methods to address challenges such as data imbalance and subjectivity in emotion labeling.",
        image: "images/Project;SER.png",
        duration: "2024-2025",
        status: "ongoing",
        details: {
          objectives: [
            "Build robust and generalizable emotion recognition representations from naturalistic speech data",
            "Explore hierarchical structures in speech (e.g., word-, utterance-, and embedding-level features)",
            "Mitigate biases caused by data imbalance and emotional ambiguity using advanced loss functions and ensemble strategies"
          ],
          technologies: ["Audio Processing", "Natural Language Processing", "Multimodal Fusion", "Emotion Recognition"],
          team: ["Hyo Jin Jon", "Longbin Jin", "Hyuntaek Jung", "Hyunseo Kim", "Donghun Min", "Heejae Choi", "Shinwoo Ham", "Junil Jeon", "Myeonghun Jung"],
        }
      },
      {
        id: 6,
        title: "Time Series Anomaly Detection",
        category: "Signal Processing & Industry",
        description: "This project investigates anomaly detection methods for complex multivariate time series data. Our goal is to extract spatial and temporal representations from multi-channel signals (e.g., sensor streams, physiological signals) and to detect subtle or abrupt deviations indicative of system failures, health anomalies, or external events.",
        image: "images/Project;TSAD.png",
        duration: "2024-2025",
        status: "ongoing",
        details: {
          objectives: [
            "Build expressive spatial representations from high-dimensional time series data",
            "Analyze multi-channel dependencies and temporal patterns",
            "Detect anomalies in dynamic systems with noisy or partially observed data"
          ],
          technologies: ["Multivariate Signal Analysis", "Anomaly Detection"],
          team: ["Hyuntaek Jung", "Shinwoo Ham", "Yealim Oh"],
        }
      },
      {
        id: 5,
        title: "EEG Signal Analysis with Domain Adaptation",
        category: "Signal Processing & Biomedical",
        description: "This project aims to design lightweight and scalable domain adaptation techniques for EEG-based signal analysis. Given the variability in EEG signals across subjects and sessions, we develop methods to adapt models to unseen domains with minimal retraining. Applications include emotion recognition, cognitive state monitoring, and neurological anomaly detection.",
        image: "images/Project;EEG.png",
        duration: "2023-2025",
        status: "ongoing",
        details: {
          objectives: [
            "Develop multimodal fusion strategies for video understanding",
            "Implement attention mechanisms for temporal modeling",
            "Achieve state-of-the-art performance on benchmark datasets"
          ],
          technologies: ["Biomedical Analysis", "Electroencephalography (EEG) Signal Analysis", "Domain Adaptation"],
          team: ["Hyunseo Kim", "Heejae Choi"],
        }
      },
      {
        id: 4,
        title: "Speech Anomaly Detection in Syllable-level",
        category: "Signal Processing & Biomedical",
        description: "This project explores a subject-agnostic approach to early detection of hearing impairment by analyzing fine-grained anomalies in speech. Unlike conventional pure tone tests, we focus on real-world word recognition tasks and segment the data into phoneme-level audio units. By learning the distribution of normal speech patterns in a semi-supervised manner, the system can localize abnormal acoustic patterns and estimate the severity of hearing impairment.",
        image: "images/Project;Syllable.PNG",
        duration: "2024-2025",
        status: "ongoing",
        details: {
          objectives: [
            "Detect early signs of hearing loss by analyzing speech at the phoneme level",
            "Model normal acoustic patterns using semi-supervised learning",
            "Compute phoneme-level anomaly scores to localize abnormalities",
            "Enable objective, non-invasive, and scalable screening for hearing impairment"
          ],
          technologies: ["Speech Analysis", "Task Design", "Multimodality"],
          team: ["Longbin Jin", "Donghun Min"],
        }
      },
      {
        id: 3,
        title: "Gaze Analysis for Alzheimer's Disease Detection",
        category: "Signal Processing & Biomedical",
        description: "This project introduces a non-invasive, video-based framework for detecting Alzheimer's Disease (AD) by analyzing gaze patterns and head movements. We propose GazeMap, a novel method to transform time-series gaze data into spatial representations. A dual-pathway CNN then processes gaze and head pose separately before fusion, capturing both short- and long-term behavioral cues. Our model achieves high accuracy even in real-world out-of-distribution settings and provides interpretable visualizations of AD-related gaze behavior.",
        image: "images/Project;Gaze.PNG",
        duration: "2024-2025",
        status: "ended",
        details: {
          objectives: [
            "Detect Alzheimer's Disease using gaze and head movement patterns",
            "Design GazeMap: 1D-to-2D transformation of gaze/head pose for enhanced learning",
            "Train a dual-pathway CNN for multimodal behavioral analysis",
            "Ensure generalization to both clinical and real-world environments",
            "Provide interpretable saliency maps for understanding gaze abnormalities in AD"
          ],
          technologies: ["Gaze Analysis", "Representation Learning"],
          team: ["Hyuntaek Jung", "Shinwoo Ham"],
        }
      },
      {
        id: 2,
        title: "Domain Adaptation for Video Action Recognition",
        category: "Computer Vision",
        description: "This project focuses on enhancing video action recognition in out-of-domain environments by leveraging CLIP-based visual representations. We explore visual prompt tuning as a parameter-efficient alternative to traditional fine-tuning and develop input-customized prompts that dynamically adapt to target domains. The goal is to maintain recognition accuracy while minimizing computational costs and annotation efforts.",
        image: "images/Project;VideoActionRecognition.PNG",
        duration: "2023-2025",
        status: "ended",
        details: {
          objectives: [
            "Perform efficient domain adaptation for video action recognition using CLIP",
            "Implement visual prompt tuning for lightweight adaptation",
            "Design input-dependent prompt learning to tailor prompts to specific domains",
            "Improve performance in low-light, egocentric, and cross-dataset settings",
          ],
          technologies: ["Multimodality", "Domain Adaptation", "Few-shot Learning", "Prompt Learning"],
          team: ["Longbin Jin", "Hyuntaek Jung", "Hyojin Jon"],
        }
      },
      {
        id: 1,
        title: "Alzheimer's Disease Detection from Spontaneous Speech",
        category: "Signal Processing & Biomedical",
        description: "This project aims to detect Alzheimer’s Disease through acoustic cues in natural, spontaneous speech, without relying on language transcripts or structured prompts. The system is trained to recognize cognitive decline markers from speech prosody, rhythm, and voice quality. Additionally, we expand this framework to support multilingual detection, making it more inclusive and applicable across different populations.",
        image: "images/Project;AD.png",
        duration: "2023-2025",
        status: "ongoing",
        details: {
          objectives: [
            "Detect Alzheimer's Disease using only acoustic features from spontaneous speech",
            "Eliminate reliance on transcripts or language-specific models",
            "Develop robust models for multilingual AD detection",
            "Enable early, scalable, and language-agnostic diagnosis using speech data"
          ],
          technologies: ["Speech Analysis", "Task Design"],
          team: ["Longbin Jin", "Yealim Oh", "Hyunseo Kim", "Hyuntaek Jung", "Hyojin Jon", "Donghun Min"],
        }
      }
      
    ];

    // Before rendering project blocks, sort projectsData by id descending
    const sortedProjectsData = projectsData.slice().sort((a, b) => b.id - a.id);

    // Use sortedProjectsData instead of projectsData in loadProjects()
    function loadProjects() {
      const projectsGrid = document.querySelector('.projects-grid');
      projectsGrid.innerHTML = '';
      sortedProjectsData.forEach((project, idx) => {
        const projectCard = document.createElement('div');
        projectCard.className = 'project-card';
        projectCard.onclick = () => showProjectDetail(idx);
        
        projectCard.innerHTML = `
          <img src="${project.image}" alt="${project.title}" class="project-image">
          <div class="project-category">${project.category}</div>
          <div class="project-title">${project.title}</div>
          <div class="project-description">${project.description}</div>
          <div class="project-meta">
            <span class="project-duration">${project.duration}</span>
            <span class="project-status status-${project.status}">${project.status}</span>
          </div>
        `;
        
        projectsGrid.appendChild(projectCard);
      });
    }

    // Project modal functionality
    const projectModal = document.getElementById('projectModal');
    const projectModalContent = document.getElementById('projectModalContent');
    const projectModalClose = document.querySelector('.project-modal-close');

    // Close modal when clicking X or outside
    projectModalClose.onclick = function() {
      projectModal.style.display = "none";
    }

    window.onclick = function(event) {
      if (event.target == projectModal) {
        projectModal.style.display = "none";
      }
      if (event.target == newsModal) {
        newsModal.style.display = "none";
      }
    }

    // Show project detail in modal
    window.showProjectDetail = function(index) {
      const project = sortedProjectsData[index];
      if (project) {
        const imageHtml = project.image ? `<img src="${project.image}" alt="${project.title}" class="project-image">` : '';
        const objectivesHtml = project.details.objectives.map(obj => `<li>${obj}</li>`).join('');
        const technologiesHtml = project.details.technologies.map(tech => `<li>${tech}</li>`).join('');
        const teamHtml = project.details.team.map(member => `<li>${member}</li>`).join('');
        
        projectModalContent.innerHTML = `
          <h2>${project.title}</h2>
          <div class="project-category">${project.category}</div>
          <div class="project-duration">Duration: ${project.duration}</div>
          ${imageHtml}
          <div class="project-description">${project.description}</div>
          
          <div class="project-objectives">
            <h3>Objectives</h3>
            <ul>${objectivesHtml}</ul>
          </div>
          
          <div class="project-technologies">
            <h3>Technologies</h3>
            <ul>${technologiesHtml}</ul>
          </div>
          
          <div class="project-team">
            <h3>Team Members</h3>
            <ul>${teamHtml}</ul>
          </div>
          
          <div class="project-status status-${project.status}">${project.status}</div>
        `;
        projectModal.style.display = "block";
      }
    }

    // Load projects when page loads
    loadProjects();

    // ----- Members: 데이터 -----
    const membersData = [
      {
        id: 1,
        name: "Eun Yi Kim",
        role: "Professor",
        email: "eykim@konkuk.ac.kr",
        image: "images/empty.png",
        researchAreas: [
          "Computer Vision",
          "Signal Processing",
          "Deep Learning",
          "Human-Computer Interaction",
          "Biomedical Signal Processing"
        ],
        education: [
          "M.S. in Computer Engineering from the Kyungpook National University, Korea (1999)",
          "Ph.D. in Computer Engineering from the Kyungpook National University, Korea (2001)"
        ],
      },
      {
        id: 2,
        name: "Longbin Jin",
        role: "Ph.D. Graduate",
        email: "jinlongbin@konkuk.ac.kr, lbjin@voinosis.com",
        image: "images/김룡빈.jpg",
        researchInterests: [
          "Computer Vision",
          "Signal Processing",
          "Biomedical Signal Processing",
          "Deep Learning",
          "Anomaly Detection"
        ],
        admissionDate: "2018-09",
        awards: [
          "HCI Korea 2025 Best Paper Award", 
          "KSC 2023 학부생부문 우수상",
          "2023 대한전자공학회 하계학술대회 우수학생논문상",
          "KSC 2020 학부생부문 장려상 "
        ],
        publications: [
          "EV-CLIP: Efficient Visual Prompt Adaptation for CLIP in Few-Shot Action Recognition under Visual Challenges (Pattern Recognition; Submitted)",
          "Contrastive Learning-based Syllable-Level Mispronunciation Detection and Diagnosis for Speech Audiometry (INTERSPEECH 2025)",
          "MATER: Multi-level Acoustic and Textual Emotion Representation for Interpretable Speech Emotion Recognition (INTERSPEECH 2025)",
          "Audio Prompt Driven Reprogramming for Diagnosing Major Depressive Disorder (Pattern Recognition Letters; Under Review)",
          "Watermark and Trademark Prompts Boost Video Action Recognition in Visual-Language Models (Mathematics)",
          "Detecting Hearing Impairment through Localizing Abnormal Speech Patterns (IEEE Signal Processing Letters)",
          "Identifying Alzheimer’s Disease Across Cognitive Impairment Spectrum Using Acoustic Features Only (ICPR 2024)",
          "EEG-RegNet: Regressive Emotion Recognition in Continuous VAD Space Using EEG Signals (Mathematics)",
          "이상 발화 패턴 탐지를 통한 난청 분류 (대한전자공학회 하계학술대회 2024)",
          "EEG-based Emotion Estimation with Bernoulli Penalty and Weighted MSE-CE (KSC 2023)",
          "Consen: Complementary and simultaneous ensemble for alzheimer’s disease detection and mmse score prediction (ICASSP 2023)",
          "알츠하이머 진단 및 중증도 예측을 위한 단일화된 딥러닝 아키텍처 연구 (대한전자공학회 하계학술대회 2023)",
          "딥러닝을 이용한 음성기반의 난청 인식 연구 (대한전자공학회 하계학술대회 2023)",
          "E-EmotiConNet: EEG-based emotion recognition with context information (IJCNN 2022)",
          "GViT: Locality enhanced vision transformer using spectral graph convolutional network (IJCNN 2022)",
          "세그멘테이션을 기반한 이미지 복원 모델 (HCI Korea 2022)",
          "Interpretable Cross-Subject EEG-Based Emotion Recognition Using Channel-Wise Features (Sensors)",
          "Emotion Recognition based BCI using Channel-wise Features (CHI 2020)",
          "Channel-wise Features 를 이용한 뇌파 기반 개인 인식 (KSC 2019)",
          "뇌파를 이용한 감정 인식에서의 공간적 및 시간적 특징 추출 방법 제시 (KSC 2019)",
          "LSTM 구조를 이용한 뇌파 기반 위험 상황 인식 (KSC 2019)",
          "Eeg-based user identification using channel-wise features (ACPR 2019)",
          "BalanceNet 을 이용한 트윗에서의 감성 인식 (KCC 2019)",
          "Understanding Individuals' Psychological Behavior from Social Media Data (ICIGP 2019)",
          "Pedestrian Detection using Spatial Haar-like Features (ICCT 2018)",
        ],
        projects: [
          "Speech Anomaly Detection in Syllable-level",
          "Speech Emotion Recognition using Deep Learning",
          "EEG Signal Analysis with Domain Adaptation",
          "Domain Adaptation for Video Action Recognition",
          "Alzheimer's Disease Detection from Spontaneous Speech"
        ]
      },
      {
        id: 3,
        name: "Yealim Oh",
        role: "Master Student",
        email: "dodoh0125@konkuk.ac.kr",
        image: "images/오예림.jpg",
        researchInterests: [
          "Computer Vision",
          "Signal Processing",
          "Biomedical Signal Processing",
          "Deep Learning",
          "Anomaly Detection"
        ],
        admissionDate: "2023-03",
        awards: [],
        publications: [
          "딥러닝을 이용한 음성기반의 난청 인식 연구 (대한전자공학회 하계학술대회 2023)",
          "Consen: Complementary and simultaneous ensemble for alzheimer’s disease detection and mmse score prediction (ICASSP 2023)",
        ],
        projects: [
          "Anomaly Detection for Parkinson's Disease",
          "Alzheimer's Disease Detection from Spontaneous Speech"
        ]
      },
      {
        id: 4,
        name: "Hyo Jin Jon",
        role: "Master Student",
        email: "hyojin2011@konkuk.ac.kr",
        image: "images/전효진.jpg",
        researchInterests: [
          "Emotion Recognition",
          "Speech Analysis",
          "Computer Vision",
          "Multimodal Fusion",
        ],
        admissionDate: "2024-03",
        awards: [
          "KSC 2023 학부생부문 우수상",
          "2023 KU SW경진대회 심사위원특별상",
          "2023 대한전자공학회 하계학술대회 우수학생논문상"
        ],
        publications: [
          "EV-CLIP: Efficient Visual Prompt Adaptation for CLIP in Few-Shot Action Recognition under Visual Challenges (Pattern Recognition; Submitted)",
          "MATER: Multi-level Acoustic and Textual Emotion Representation for Interpretable Speech Emotion Recognition (INTERSPEECH 2025)",
          "Watermark and Trademark Prompts Boost Video Action Recognition in Visual-Language Models (Mathematics)",
          "음악 소리에 대한 반응으로부터 감정을 인식하기 위한 뇌파 기반 감정인식 프레임워크 (HCI Korea 2025)",
          "Identifying Alzheimer’s Disease Across Cognitive Impairment Spectrum Using Acoustic Features Only (ICPR 2024)",
          "EEG-RegNet: Regressive Emotion Recognition in Continuous VAD Space Using EEG Signals (Mathematics)",
          "EEG-based Emotion Estimation with Bernoulli Penalty and Weighted MSE-CE (KSC 2023)",
          "알츠하이머 진단 및 중증도 예측을 위한 단일화된 딥러닝 아키텍처 연구 (대한전자공학회 하계학술대회 2023)",
          "Consen: Complementary and simultaneous ensemble for alzheimer’s disease detection and mmse score prediction (ICASSP 2023)",
        ],
        projects: [
          "Speech Emotion Recognition using Deep Learning",
          "Domain Adaptation for Video Action Recognition",
          "Emotion Recognition using EEG Signals",
          "Alzheimer's Disease Detection from Spontaneous Speech"
        ]
      },
      {
        id: 5,
        name: "Hyuntaek Jung",
        role: "Master Student",
        email: "busan199@konkuk.ac.kr",
        image: "images/정현택.jpg",
        researchInterests: [
          "Time Series Analysis",
          "Anomaly Detection",
          "Signal Processing"
        ],
        admissionDate: "2024-03",
        awards: [
          "HCI Korea 2025 Best Paper Award", 
          "KSC 2023 학부생부문 우수상",
          "2023 KU SW경진대회 심사위원특별상",
          "2023 대한전자공학회 하계학술대회 우수학생논문상"
        ],
        publications: [
          "Enhancing Multivariate Time Series Anomaly Detection with 2D Spatial Representations and Channel Attention (IEEE Signal Processing Letters; Under Review)", 
          "MATER: Multi-level Acoustic and Textual Emotion Representation for Interpretable Speech Emotion Recognition (INTERSPEECH 2025)",
          "GazeMap: Dual-Pathway CNN Approach for Diagnosing Alzheimer’s Disease from Gaze and Head Movements (Mathematics)",
          "Watermark and Trademark Prompts Boost Video Action Recognition in Visual-Language Models (Mathematics)",
          "Two-stream에서의 사용자의 얼굴 특징 추적 기반의 치매 조기 진단 시스템 개발 (HCI Korea 2025)",
          "Identifying Alzheimer’s Disease Across Cognitive Impairment Spectrum Using Acoustic Features Only (ICPR 2024)",
          "EEG-RegNet: Regressive Emotion Recognition in Continuous VAD Space Using EEG Signals (Mathematics)",
          "EEG-based Emotion Estimation with Bernoulli Penalty and Weighted MSE-CE (KSC 2023)",
          "알츠하이머 진단 및 중증도 예측을 위한 단일화된 딥러닝 아키텍처 연구 (대한전자공학회 하계학술대회 2023)",
          "Consen: Complementary and simultaneous ensemble for alzheimer’s disease detection and mmse score prediction (ICASSP 2023)",
        ],
        projects: [
          "Time Series Anomaly Detection",
          "Gaze Analysis for Alzheimer's Disease Detection",
          "Domain Adaptation for Video Action Recognition",
          "Emotion Recognition using EEG Signals",
          "Alzheimer's Disease Detection from Spontaneous Speech"
        ]
      },
      {
        id: 6,
        name: "Hyunseo Kim",
        role: "Master Student",
        email: "hs11015@konkuk.ac.kr",
        image: "images/김현서.jpg",
        researchInterests: [
          "EEG Signal Analysis",
          "Machine Learning",
          "Domain Adaptation",
          "Biomedical Engineering"
        ],
        admissionDate: "2024-09",
        awards: [
          "KSC 2023 학부생부문 우수상",
          "2023 KU SW경진대회 심사위원특별상",
        ],
        publications: [
          "PEARL: Prompt-based EEG Adaptation via Resource-efficient Learning (IEEE Transactions on Biomedical Engineering; Submitted)",
          "MATER: Multi-level Acoustic and Textual Emotion Representation for Interpretable Speech Emotion Recognition (INTERSPEECH 2025)",
          "Audio Prompt Driven Reprogramming for Diagnosing Major Depressive Disorder (Pattern Recognition Letters; Under Review)",
          "음악 소리에 대한 반응으로부터 감정을 인식하기 위한 뇌파 기반 감정인식 프레임워크 (HCI Korea 2025)",
          "EEG-RegNet: Regressive Emotion Recognition in Continuous VAD Space Using EEG Signals (Mathematics)",
          "EEG-based Emotion Estimation with Bernoulli Penalty and Weighted MSE-CE (KSC 2023)",
          "딥러닝을 이용한 음성기반의 난청 인식 연구 (대한전자공학회 하계학술대회 2023)",
          "Consen: Complementary and simultaneous ensemble for alzheimer’s disease detection and mmse score prediction (ICASSP 2023)",
        ],
        projects: [
          "EEG Signal Analysis with Domain Adaptation",
          "Speech Emotion Recognition using Deep Learning",
          "Emotion Recognition using EEG Signals",
          "Alzheimer's Disease Detection from Spontaneous Speech"
        ]
      },
      {
        id: 7,
        name: "Heejae Choi",
        role: "Master Student",
        email: "qkw1205@konkuk.ac.kr",
        image: "images/최희재.jpg",
        researchInterests: [
          "EEG Signal Analysis",
          "Machine Learning",
          "Domain Adaptation",
          "Biomedical Engineering"
        ],
        admissionDate: "2024-03",
        awards: [],
        publications: [
          "PEARL: Prompt-based EEG Adaptation via Resource-efficient Learning (IEEE Transactions on Biomedical Engineering; Submitted)",
          "음악 소리에 대한 반응으로부터 감정을 인식하기 위한 뇌파 기반 감정인식 프레임워크 (HCI Korea 2025)",
        ],
        projects: [
          "EEG Signal Analysis with Domain Adaptation",
          "Speech Emotion Recognition using Deep Learning",
          "Emotion Recognition using EEG Signals"
        ]
      },
      {
        id: 8,
        name: "Shinwoo Ham",
        role: "Master Student",
        email: "gka0656@konkuk.ac.kr",
        image: "images/함신우.jpg",
        researchInterests: [
          "Time Series Analysis",
          "Anomaly Detection",
          "Signal Processing"
        ],
        admissionDate: "2024-03",
        awards: [
          "HCI Korea 2025 Best Paper Award", 
        ],
        publications: [
          "Enhancing Multivariate Time Series Anomaly Detection with 2D Spatial Representations and Channel Attention (IEEE Signal Processing Letters; Under Review)", 
          "GazeMap: Dual-Pathway CNN Approach for Diagnosing Alzheimer’s Disease from Gaze and Head Movements (Mathematics)",
          "Two-stream에서의 사용자의 얼굴 특징 추적 기반의 치매 조기 진단 시스템 개발 (HCI Korea 2025)",
        ],
        projects: [
          "Time Series Anomaly Detection",
          "Speech Emotion Recognition using Deep Learning",
        ]
      },
      {
        id: 9,
        name: "Donghun Min",
        role: "Master Student",
        email: "mindonghun@konkuk.ac.kr",
        image: "images/민동훈.jpg",
        researchInterests: [
          "Speech Processing",
          "Audio Analysis",
          "Deep Learning"
        ],
        admissionDate: "2025-09",
        awards: [],
        publications: [
          "Contrastive Learning-based Syllable-Level Mispronunciation Detection and Diagnosis for Speech Audiometry (INTERSPEECH 2025)",
          "MATER: Multi-level Acoustic and Textual Emotion Representation for Interpretable Speech Emotion Recognition (INTERSPEECH 2025)",
          "Detecting Hearing Impairment through Localizing Abnormal Speech Patterns (IEEE Signal Processing Letters)",
          "이상 발화 패턴 탐지를 통한 난청 분류 (대한전자공학회 하계학술대회 2024)",
        ],
        projects: [
          "Speech Anomaly Detection in Syllable-level",
          "Speech Emotion Recognition using Deep Learning",
          "Alzheimer's Disease Detection from Spontaneous Speech"
        ]
      },
      {
        id: 10,
        name: "Junil Jeon",
        role: "Master Student",
        email: "jeonjunil@konkuk.ac.kr",
        image: "images/전준일.jpg",
        researchInterests: [
          "Speech Processing",
          "Audio Analysis",
          "Deep Learning"
        ],
        admissionDate: "2025-09",
        awards: [],
        publications: [],
        projects: [
          "Speech Emotion Recognition using Deep Learning"
        ]
      },
      {
        id: 11,
        name: "Myeonghun Jung",
        role: "Undergraduate Student",
        email: "jmfc02@naver.com",
        image: "images/empty.png",
        researchInterests: [
          "Speech Analysis",
          "Computer Vision",
          "Machine Learning",
          "Deep Learning"
        ],
        admissionDate: "2025-07",
        awards: [],
        publications: [],
        projects: [
          "Speech Emotion Recognition using Deep Learning"
        ]
      }
    ];

    // Member modal functionality
    const memberModal = document.getElementById('memberModal');
    const memberModalContent = document.getElementById('memberModalContent');
    const memberModalClose = document.querySelector('.member-modal-close');

    // Close modal when clicking X or outside
    memberModalClose.onclick = function() {
      memberModal.style.display = "none";
    }

    window.onclick = function(event) {
      if (event.target == memberModal) {
        memberModal.style.display = "none";
      }
      if (event.target == newsModal) {
        newsModal.style.display = "none";
      }
      if (event.target == projectModal) {
        projectModal.style.display = "none";
      }
    }

    // Show member detail in modal
    window.showMemberDetail = function(memberId) {
      const member = membersData.find(m => m.id === memberId);
      if (member) {
        // Helper for comma-separated list
        const commaList = arr => arr && arr.length ? arr.join(', ') : '';
        // Helper for section (only if content is not empty)
        const section = (title, content) => {
          if (!content || (typeof content === 'string' && content.trim() === '')) return '';
          return `
            <div class="member-section">
              <div class="member-section-title">${title}</div>
              <div class="member-section-content">${content}</div>
            </div>
          `;
        };
        let html = `
          <h2>${member.name}</h2>
          <div class="member-role">${member.role}</div>
          <div class="member-email">${member.email}</div>
          <img src="${member.image}" alt="${member.name}" class="member-image">
        `;
        if (member.role === "Professor") {
          // Projects first
          html += section('Research Areas', commaList(member.researchAreas));
          // Education as bullet points if array, else as text
          if (Array.isArray(member.education)) {
            html += section('Education', `<ul style='margin:0 0 0 1.2em;padding:0;'>${member.education.map(e => `<li>${e}</li>`).join('')}</ul>`);
          } else {
            html += section('Education', member.education);
          }
        } else {
          // For students, only render non-empty sections
          if (member.projects && member.projects.length) {
            html += section('Projects', member.projects.map(p => `<div>${p}</div>`).join(''));
          }
          if (member.researchInterests && member.researchInterests.length) {
            html += section('Research Interests', commaList(member.researchInterests));
          }
          if (member.admissionDate && member.admissionDate.trim() !== '') {
            html += section('Admission Date', member.admissionDate);
          }
          if (member.awards && member.awards.length) {
            html += section('Awards', member.awards.map(a => `<div>${a}</div>`).join(''));
          }
          if (member.publications && member.publications.length) {
            html += section('Publications', `<ul style='margin:0 0 0 1.2em;padding:0;'>${member.publications.map(p => `<li>${p}</li>`).join('')}</ul>`);
          }
        }
        memberModalContent.innerHTML = html;
        memberModal.style.display = "block";
      }
    }

    // Add click handlers to member cards
    document.addEventListener('DOMContentLoaded', function() {
      const memberCards = document.querySelectorAll('.member-card');
      memberCards.forEach((card, index) => {
        card.style.cursor = 'pointer';
        card.onclick = () => {
          // Find member by name (since we don't have IDs in HTML)
          const memberName = card.querySelector('.member-name').textContent;
          const member = membersData.find(m => m.name === memberName);
          if (member) {
            showMemberDetail(member.id);
          }
        };
      });
    });

    // ----- Publications: 예시 데이터 -----
    const pubData = [
    {
        title: "PEARL: Prompt-based EEG Adaptation via Resource-efficient Learning",
        authors: "H Kim, H Choi, EY Kim",
        venue: "IEEE Transactions on Biomedical Engineering; Submitted",
		type:"Journal",
		date: 2025,
        link: ""
      },
    {
        title: "Enhancing Multivariate Time Series Anomaly Detection with 2D Spatial Representations and Channel Attention",
        authors: "S Ham, H Jung, EY Kim",
        venue: "IEEE Signal Processing Letters; Under Review",
		type:"Journal",
		date: 2025,
        link: ""
      },
    {
        title: "EV-CLIP: Efficient Visual Prompt Adaptation for CLIP in Few-Shot Action Recognition under Visual Challenges",
        authors: "HJ Jon, L Jin, EY Kim",
        venue: "Pattern Recognition; Submitted",
		type:"Journal",
		date: 2025,
        link: ""
      },
	  {
        title: "Contrastive Learning-based Syllable-Level Mispronunciation Detection and Diagnosis for Speech Audiometry",
        authors: "L Jin, D Min, JE Shin, EY Kim",
        venue: "INTERSPEECH 2025; Accepted",
		type:"Conference",
		date: 2025,
        link: ""
      },
	  {
        title: "MATER: Multi-level Acoustic and Textual Emotion Representation for Interpretable Speech Emotion Recognition",
        authors: "HJ Jon, L Jin, H Jung, H Kim, D Min, EY Kim",
        venue: "INTERSPEECH 2025; Accepted",
		type:"Conference",
		date: 2025,
        link: ""
      },
    {
        title: "Audio Prompt Driven Reprogramming for Diagnosing Major Depressive Disorder",
        authors: "H Kim, L Jin, EY Kim",
        venue: "Pattern Recognition Letters; Under Review",
		type:"Journal",
		date: 2025,
        link: ""
      },
	  {
        title: "GazeMap: Dual-Pathway CNN Approach for Diagnosing Alzheimer’s Disease from Gaze and Head Movements", 
        authors: "H Jung, S Ham, JE Shin, H Kil, EY Kim",
        venue: "Mathematics 13 (11), 1867",
		type:"Journal",
		date: 2025,
        link: ""
      },
      {
        title: "Watermark and Trademark Prompts Boost Video Action Recognition in Visual-Language Models",
        authors: "L Jin, H Jung, HJ Jon, EY Kim",
        venue: "Mathematics 13 (9), 1365",
		type:"Journal",
		date: 2025,
        link: ""
      },
      {
        title: "Detecting Hearing Impairment through Localizing Abnormal Speech Patterns",
        authors: "L Jin, D Min, CH Yu, JE Shin, EY Kim",
        venue: "IEEE Signal Processing Letters",
		type:"Journal",
		date:2025,
        link: ""
      },
      {
        title: "Identifying Alzheimer’s Disease Across Cognitive Impairment Spectrum Using Acoustic Features Only",
        authors: "HJ Jon, H Jung, L Jin, EY Kim",
        venue: "International Conference on Pattern Recognition, 402-413",
		type:"Conference",
		date:2024,
        link: ""
      },
      {
        title: "EEG-RegNet: Regressive Emotion Recognition in Continuous VAD Space Using EEG Signals",
        authors: "HJ Jon, L Jin, H Jung, H Kim, EY Kim",
        venue: "Mathematics 13 (1), 87",
		type:"Journal",
		date:2024,
        link: ""
      },
      {
        title: "Consen: Complementary and simultaneous ensemble for alzheimer’s disease detection and mmse score prediction",
        authors: "L Jin, Y Oh, H Kim, H Jung, HJ Jon, JE Shin, EY Kim",
        venue: "ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
		type:"Conference",
		date:2023,
        link: ""
      },
      {
        title: "E-EmotiConNet: EEG-based emotion recognition with context information",
        authors: "L Jin, EY Kim",
        venue: "2022 International Joint Conference on Neural Networks (IJCNN), 1-8",
		type:"Conference",
		date:2022,
        link: ""
      },
      {
        title: "GViT: Locality enhanced vision transformer using spectral graph convolutional network",
        authors: "L Jin, EY Kim",
        venue: "2022 International Joint Conference on Neural Networks (IJCNN), 1-6",
		type:"Conference",
		date:2022,
        link: ""
      },
      {
        title: "Interpretable Cross-Subject EEG-Based Emotion Recognition Using Channel-Wise Features†",
        authors: "L Jin, EY Kim",
        venue: "Sensors 20 (23), 6719",
		type:"Journal",
		date:2020,
        link: ""
      },
      {
        title: "Eeg-based user identification using channel-wise features",
        authors: "L Jin, J Chang, E Kim",
        venue: "Pattern Recognition: 5th Asian Conference, ACPR 2019, Auckland, New Zealand, November 26–29, 2019, Revised Selected Papers, Part II 5",
		type:"Conference",
		date:2020,
        link: ""
      },
	  {
        title: "Monitoring Mood Trends of Twitter Users using Multi-modal Analysis method of Texts and Images",
        authors: "EY Kim, E Ko",
        venue: "Journal of the Korea Convergence Society 9 (1), 419-431",
		type:"Journal",
		date:2018,
        link: ""
      },
      {
        title: "A vision-based wayfinding system for visually impaired people using situation awareness and activity-based instructions",
        authors: "E Ko, EY Kim",
        venue: "Sensors 17 (8), 1882",
		type:"Journal",
		date:2017,
        link: ""
      },
      {
        title: "Vision‐based wheelchair navigation using geometric AdaBoost learning",
        authors: "EY Kim",
        venue: "Electronics Letters 53 (8), 534-536",
		date:2017,
		type:"Journal",
        link: ""
      },
      {
        title: "Summarizing Social Image Search Results using Human Affects",
        authors: "E Ko, EY Kim, Y Yu",
        venue: "Companion Proceedings of the 22nd International Conference on Intelligent User Interfaces",
		date:2017,
		type:"Conference",
        link: ""
      },
      {
        title: "MRF model based real‐time traffic flow prediction with support vector regression",
        authors: "EY Kim",
        venue: "Electronics Letters 53 (4), 243-245",
		date:2017,
		type:"Journal",
        link: ""
      },
      {
        title: "Wheelchair navigation system for disabled and elderly people",
        authors: "EY Kim",
        venue: "Sensors 16 (11), 1806",
		date:2016,
		type:"Journal",
        link: ""
      },
      {
        title: "Canonical image selection based on human affects in photographic images",
        authors: "EY Kim, E Ko",
        venue: "Image and Vision Computing 54, 83-98",
		date:2016,
		type:"Journal",
        link: ""
      },
      {
        title: "Outdoor Context Awareness Device That Enables Mobile Phone Users to Walk Safely through Urban Intersections.",
        authors: "J Hwang, Y Ji, N Kwak, EY Kim",
        venue: "ICPRAM, 526-533",
		date:2016,
		type:"Conference",
        link: ""
      },
      {
        title: "3D Markov process for traffic flow prediction in real-time",
        authors: "E Ko, J Ahn, EY Kim",
        venue: "Sensors 16 (2), 147",
		date:2016,
		type:"Journal",
        link: ""
      },
      {
        title: "Identifying depressive users in Twitter using multimodal analysis",
        authors: "K Kang, C Yoon, EY Kim",
        venue: "2016 international conference on big data and smart computing (BigComp), 231-238",
		date:2016,
		type:"Conference",
        link: ""
      },
      {
        title: "Discovering visual features for recognizing user's sentiments in social images",
        authors: "E Ko, C Yoon, EY Kim",
        venue: "2016 international conference on big data and smart computing (bigcomp), 378-381",
		date:2016,
		type:"Conference",
        link: ""
      },
      {
        title: "Highway traffic flow prediction using support vector regression and Bayesian classifier",
        authors: "J Ahn, E Ko, EY Kim",
        venue: "2016 International conference on big data and smart computing (BigComp), 239-244",
		date:2016,
		type:"Conference",
        link: ""
      },
      {
        title: "Predicting spatiotemporal traffic flow based on support vector regression and Bayesian classifier",
        authors: "JY Ahn, E Ko, EY Kim",
        venue: "2015 IEEE fifth international conference on big data and cloud computing",
		date:2015,
		type:"Conference",
        link: ""
      },
      {
        title: "Recognizing the sentiments of web images using hand-designed features",
        authors: "E Ko, EY Kim",
        venue: "2015 IEEE 14th International Conference on Cognitive Informatics & Cognitive Computing (ICCI* CC)",
		date:2015,
		type:"Conference",
        link: ""
      },
      {
        title: "Generating summaries for photographic images based on human affects",
        authors: "EY Kim, E Ko",
        venue: "2015 IEEE 14th International Conference on Cognitive Informatics & Cognitive Computing (ICCI* CC)",
		date:2015,
		type:"Conference",
        link: ""
      },
      {
        title: "Building Image Sentiment Dataset with an Online Rating Game",
        authors: "C Yoon, KH Kang, EY Kim",
        venue: "Proceedings of the 20th International Conference on Intelligent User Interfaces",
		date:2015,
		type:"Conference",
        link: ""
      },
      {
        title: "Real-time highway traffic flow estimation based on 3D Markov Random Field",
        authors: "J Ahn, E Ko, EY Kim",
        venue: "17th International IEEE Conference on Intelligent Transportation Systems (ITSC)",
		date:2014,
		type:"Conference",
        link: ""
      },
      {
        title: "An intelligent wheelchair to enable safe mobility of the disabled people with motor and cognitive impairments",
        authors: "Y Ji, M Lee, EY Kim",
        venue: "European Conference on Computer Vision, 702-715",
		date:2014,
		type:"Conference",
        link: ""
      },
      {
        title: "Finding Relationships between Human Affects and Colors Using SVD and pLSA",
        authors: "U Akhmedjanov, E Ko, Y Shin, EY Kim",
        venue: "Mobile, Ubiquitous, and Intelligent Computing: MUSIC 2013, 347-351",
		date:2014,
		type:"Conference",
        link: ""
      },
      {
        title: "Mining salient images from a large-scale blogosphere",
        authors: "X Chen, M Chen, H Shin, EY Kim",
        venue: "8th International Conference for Internet Technology and Secured Transactions (ICITST-2013)",
		date:2013,
		type:"Conference",
        link: ""
      },
      {
        title: "Image Battle System: Collecting more trustable ground truth for Affect-based image indexing system",
        authors: "U Akhmedjanov, E Ko, EY Kim",
        venue: "Procedia-Social and Behavioral Sciences 97, 571-579",
		date:2013,
		type:"Conference",
        link: ""
      },
      {
        title: "An intelligent wheelchair using situation awareness and obstacle detection",
        authors: "Y Ji, J Hwang, EY Kim",
        venue: "Procedia-social and behavioral sciences 97, 620-628",
		date:2013,
		type:"Conference",
        link: ""
      },
      {
        title: "Genetic algorithm-based reconstruction of old films corrupted by scratches and blotches",
        authors: "EY Kim, K Kim, B Kim",
        venue: "Pattern Recognition Letters 34 (2), 226-237",
		date:2013,
		type:"Journal",
        link: ""
      },
      {
        title: "Affect-Based Retrieval of Landscape Images Using Probabilistic Affective Model",
        authors: "Y Shin, EY Kim, TE Sung",
        venue: "Human-Computer Interaction. Towards Intelligent and Implicit Interaction: 15th International Conference, HCI International 2013, Las Vegas, NV, USA, July 21-26, 2013, Proceedings, Part V 15",
		date:2013,
		type:"Conference",
        link: ""
      },
      {
        title: "Monocular vision-based collision avoidance system",
        authors: "J Hwang, Y Ji, EY Kim",
        venue: "Proceedings of the 14th international conference on Human-computer interaction with mobile devices and services companion",
		date:2012,
		type:"Conference",
        link: ""
      },
      {
        title: "Intelligent situation awareness on the EYECANE",
        authors: "J Hwang, Y Ji, EY Kim",
        venue: "Pacific Rim International Conference on Artificial Intelligence, 740-745",
		date:2012,
		type:"Conference",
        link: ""
      },
      {
        title: "Outdoor situation recognition using support vector machine for the blind and the visually impaired",
        authors: "J Hwang, K Kim, EY Kim",
        venue: "PRICAI 2012: Trends in Artificial Intelligence: 12th Pacific Rim International Conference on Artificial Intelligence, Kuching, Malaysia, September 3-7, 2012. Proceedings 12",
		date:2012,
		type:"Conference",
        link: ""
      },
      {
        title: "Situation-based indoor wayfinding system for the visually impaired",
        authors: "E Ko, JS Ju, EY Kim",
        venue: "The proceedings of the 13th international ACM SIGACCESS conference on Computers and accessibility",
		date:2011,
		type:"Conference",
        link: ""
      },
      {
        title: "VFH-based Navigation using Monocular Vision",
        authors: "SH Park, JH Hwang, JS Ju, EJ Ko, JT Ryu, EY Kim",
        venue: "Journal of Korea Society of Industrial Information Systems 16 (2), 65-72",
		date:2011,
		type:"Journal",
        link: ""
      },
      {
        title: "Automatic restoration of scratch in old archive",
        authors: "K Kim, B Kim, EY Kim",
        venue: "2010 20th International Conference on Pattern Recognition, 468-471",
		date:2010,
		type:"Conference",
        link: ""
      },
      {
        title: "Affective prediction in photographic images using probabilistic affective model",
        authors: "Y Shin, EY Kim",
        venue: "Proceedings of the ACM International Conference on Image and Video Retrieval",
		date:2010,
		type:"Conference",
        link: ""
      },
      {
        title: "Automatic textile image annotation by predicting emotional concepts from visual features",
        authors: "Y Shin, Y Kim, EY Kim",
        venue: "Image and Vision Computing 28 (3), 526-537",
		date:2010,
		type:"Journal",
        link: ""
      },
      {
        title: "Film line scratch detection using texture and shape information",
        authors: "K Kim, EY Kim",
        venue: "Pattern recognition letters 31 (3), 250-258",
		date:2010,
		type:"Journal",
        link: ""
      },
      {
        title: "Real Time Monocular Navigation using VFH",
        authors: "J Jo, JS Ju, E Ko, EY Kim",
        venue: "Proceedings of the Korea Information Processing Society Conference, 348-351",
		date:2010,
		type:"Conference",
        link: ""
      },
      {
        title: "Vision-based Real-Time Traffic Emission Monitoring System",
        authors: "Y Shin, J Jung, D Yoo, D Park, EY Kim, JH Woo, SB Lim, JS Ju",
        venue: "Proceedings of the Korea Information Processing Society Conference, 439-442",
		date:2010,
		type:"Conference",
        link: ""
      },
      {
        title: "Vision based interface system for hands free control of an intelligent wheelchair",
        authors: "JS Ju, Y Shin, EY Kim",
        venue: "Journal of neuroengineering and rehabilitation 6, 1-17",
		date:2009,
		type:"Journal",
        link: ""
      },
      {
        title: "Reconstruction of degraded images using genetic algoritm for archive film restoration",
        authors: "B Kim, K Kim, EY Kim",
        venue: "2009 16th IEEE International Conference on Image Processing (ICIP), 2765-2768",
		date:2009,
		type:"Conference",
        link: ""
      },
      {
        title: "EYECane: Navigating with camera embedded white cane for visually impaired person",
        authors: "JS Ju, E Ko, EY Kim",
        venue: "Proceedings of the 11th international ACM SIGACCESS conference on Computers and accessibility",
		date:2009,
		type:"Conference",
        link: ""
      },
      {
        title: "Intelligent wheelchair using head tilt and mouth shape",
        authors: "JS Ju, Y Shin, EY Kim",
        venue: "Electronics letters 45 (17), 873-875",
		date:2009,
		type:"Journal",
        link: ""
      },
      {
        title: "Personalized digital TV content recommendation with integration of user behavior profiling and multimodal content rating",
        authors: "H Shin, M Lee, EY Kim",
        venue: "IEEE Transactions on Consumer Electronics 55 (3), 1417-1423",
		date:2009,
		type:"Journal",
        link: ""
      },
      {
        title: "Efficient page layout analysis on small devices",
        authors: "E Han, C Wong, K Jung, K Lee, E Kim",
        venue: "Journal of Zhejiang University-SCIENCE A 10, 800-804",
		date:2009,
		type:"Journal",
        link: ""
      },
      {
        title: "A Data Management System for Distributed Real-Time Emissions and Air Pollutants Monitoring System",
        authors: "J Kim, YL Jin, SB Lim, K Jeong, JH Woo, EY Kim",
        venue: "2009 First Asian Conference on Intelligent Information and Database Systems",
		date:2009,
		type:"Conference",
        link: ""
      },
      {
        title: "Intelligent wheelchair (IW) interface using face and mouth recognition",
        authors: "JS Ju, Y Shin, EY Kim",
        venue: "Proceedings of the 14th international conference on Intelligent user interfaces",
		date:2009,
		type:"Conference",
        link: ""
      },
      {
        title: "EBIR: Emotion-based image retrieval",
        authors: "Y Kim, Y Shin, S Kim, EY Kim, H Shin",
        venue: "2009 Digest of Technical Papers International Conference on Consumer Electronics",
		date:2009,
		type:"Conference",
        link: ""
      },
      {
        title: "An intelligent wheelchair to enable mobility of severely disabled and elder people",
        authors: "E Ko, JS Ju, EY Kim, NS Goo",
        venue: "2009 Digest of Technical Papers International Conference on Consumer Electronics",
		date:2009,
		type:"Conference",
        link: ""
      },
      {
        title: "Development of Path Finding System using K-means clustering for Intelligent Wheelchair",
        authors: "D Kwak, J Lee, JS Ju, E Ko, EY Kim",
        venue: "Proceedings of the Korea Information Processing Society Conference, 381-382",
		date:2009,
		type:"Conference",
        link: ""
      },
      {
        title: "Automatic Film Restoration Using Distributed Genetic Algorithm",
        authors: "BG Kim, KT Kim, EY Kim",
        venue: "Journal of the Institute of Electronics Engineers of Korea SP 46 (2), 1-9",
		date:2009,
		type:"Journal",
        link: ""
      },
      {
        title: "Discovering and browsing of power users by social relationship analysis in large-scale online communities",
        authors: "H Shin, Z Xu, EY Kim",
        venue: "2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology",
		date:2008,
		type:"Conference",
        link: ""
      },
      {
        title: "Welfare interface implementation using multiple facial features tracking for the disabled people",
        authors: "Y Shin, JS Ju, EY Kim",
        venue: "Pattern Recognition Letters 29 (13), 1784-1796",
		date:2008,
		type:"Journal",
        link: ""
      },
      {
        title: "Emotion recognition using color and pattern in textile images",
        authors: "NY Kim, Y Shin, Y Kim, EY Kim",
        venue: "2008 IEEE Conference on Cybernetics and Intelligent Systems, 1100-1105",
		date:2008,
		type:"Conference",
        link: ""
      },
      {
        title: "Film line scratch detection using neural network and morphological filter",
        authors: "K Kim, EY Kim",
        venue: "2008 IEEE Conference on Cybernetics and Intelligent Systems, 1007-1011",
		date:2008,
		type:"Conference",
        link: ""
      },
      {
        title: "Mobile robot control using hand-shape recognition",
        authors: "JS Chang, EY Kim, HJ Kim",
        venue: "Transactions of the Institute of Measurement and Control 30 (2), 143-152",
		date:2008,
		type:"Journal",
        link: ""
      },
      {
        title: "Intelligent wheelchair using face and mouth shape recognition",
        authors: "JS Ju, YH Shin, EY Kim, SH Park",
        venue: "2008 Digest of Technical Papers-International Conference on Consumer Electronics",
		date:2008,
		type:"Conference",
        link: ""
      },
      {
        title: "Automatic Textile-Image Classification System using Human Emotion",
        authors: "YR Kim, YH Shin, EY Kim",
        venue: "Proceedings of the Korean Information Science Society Conference, 561-564",
		date:2008,
		type:"Conference",
        link: ""
      },
      {
        title: "Welfare Interface using Multiple Facial Features Tracking",
        authors: "JS Ju, YH Shin, EY Kim",
        venue: "Journal of the Institute of Electronics Engineers of Korea SP 45 (1), 75-83",
		date:2008,
		type:"Journal",
        link: ""
      },
      {
        title: "Mobile robot control using hand shape recognition",
        authors: "YR Kim, EY Kim, JS Chang, SH Park",
        venue: "Journal of the Institute of Electronics Engineers of Korea CI 45 (4), 34-40",
		date:2008,
		type:"",
        link: ""
      },
      {
        title: "Automatic film line scratch removal system based on spatial information",
        authors: "K Kim, E yi Kim",
        venue: "2007 IEEE International Symposium on Consumer Electronics, 1-5",
		date:2007,
		type:"Conference",
        link: ""
      },
      {
        title: "A Visual Navigation using color and texture",
        authors: "JS Ju, EY Kim, E Ko",
        venue: "Proceedings of the 23th IEEE Conference on Computer Vision and Pattern Recognition, San Francisco, CA, USA",
		date:2007,
		type:"Conference",
        link: ""
      },
      {
        title: "Emotion-based textile indexing system using pattern recognition",
        authors: "NY Kim, Y Shin, EY Kim",
        venue: "IEEE International Symposium on Consumer Electron 1 (1), 1-6",
		date:2007,
		type:"Conference",
        link: ""
      },
      {
        title: "Computer interface to use eye and mouse movement",
        authors: "EY Kim, SH Park, BJ Shin",
        venue: "International Conference on Multimedia Modeling, 471-478",
		date:2007,
		type:"Conference",
        link: ""
      },
      {
        title: "Digital film line scratch restoration based on Spatial Information",
        authors: "KT Kim, EC Ko, EY Kim",
        venue: "Proceedings of the Korean Information Science Society Conference, 454-459",
		date:2007,
		type:"Conference",
        link: ""
      },
      {
        title: "Eye Tracking using Neural Network and Mean-shift",
        authors: "SK Kang, KT Kim, YH Shin, NY Kim, EY Kim",
        venue: "Journal of the Institute of Electronics Engineers of Korea CI 44 (1), 56-63",
		date:2007,
		type:"Journal",
        link: ""
      },
      {
        title: "Emotion Recognition System using Neural networks in Textile images",
        authors: "NY Kim, YH Shin, S Kim, J Kim, KJ Jeong, HJ Koo, EY Kim",
        venue: "Journal of KIISE: Software and Applications 34 (9), 869-879",
		date:2007,
		type:"Journal",
        link: ""
      },
      {
        title: "Automatic Facial Expression Recognition using Tree Structures for Human Computer Interaction",
        authors: "YH Shin, JS Ju, EY Kim, T Kurata, AK Jain, SH Park, KC Jung",
        venue: "Journal of Korea Society of Industrial Information Systems 12 (3), 60-68",
		date:2007,
		type:"Journal",
        link: ""
      },
      {
        title: "ACMs-based Human Shape Extraction and Tracking System for Human Identification",
        authors: "SH Park, KS Kwon, EY Kim, HJ Kim",
        venue: "Journal of Korea Society of Industrial Information Systems 12 (5), 39-46",
		date:2007,
		type:"Journal",
        link: ""
      },
      {
        title: "“Shooting a Bird”: Game System Using Facial Feature for the Handicapped People",
        authors: "J Ju, Y Shin, EY Kim",
        venue: "Human-Computer Interaction. HCI Intelligent Multimodal Interaction Environments: 12th International Conference, HCI International 2007, Beijing, China, July 22-27, 2007, Proceedings, Part III 12",
		date:2007,
		type:"Conference",
        link: ""
      },
	  {
		title: "Human shape tracking for gait recognition using active contours with mean shift",
		authors: "KS Kwon, SH Park, EY Kim, HJ Kim",
		venue: "Human-Computer Interaction. HCI Intelligent Multimodal Interaction Environments: 12th International Conference, HCI International 2007, Beijing, China, July 22-27, 2007, Proceedings, Part III 12",
		date:2007,
		type:"Conference",
		link: ""
	  },
      {
		  title: "Emotion-based textile indexing using neural networks",
		  authors: "NY Kim, Y Shin, EY Kim",
		  venue: "Human-Computer Interaction. HCI Intelligent Multimodal Interaction Environments: 12th International Conference, HCI International 2007, Beijing, China, July 22-27, 2007, Proceedings, Part III 12",
		  date:2007,
		  type:"Conference",
		  link: ""
		},
		{
			title: "Lip contour extraction using level set curve evolution with shape constraint",
			authors: "JS Chang, EY Kim, SH Park",
			venue: "Human-Computer Interaction. HCI Intelligent Multimodal Interaction Environments: 12th International Conference, HCI International 2007, Beijing, China, July 22-27, 2007, Proceedings, Part III 12",
			date:2007,
			type:"Conference",
			link: ""
		},
		{
		  title: "Facial boundary detection with an active contour model",
		  authors: "JS Chang, EY Kim, HJ Kim",
		  venue: "Pattern recognition letters 28 (1), 64-74",
		  date:2007,
		  type:"Journal",
		  link: ""
		},
      {
        title: "Welfare interface using multiple facial features tracking",
        authors: "Y Shin, EY Kim",
        venue: "Australasian Joint Conference on Artificial Intelligence, 453-462",
		date:2006,
		type:"Conference",
        link: ""
      },
      {
        title: "Hand shape recognition using a mean-shift embedded active contour (MEAC)",
        authors: "EY Kim",
        venue: "International Conference on Artificial Reality and Telexistence, 1333-1341",
		date:2006,
		type:"Conference",
        link: ""
      },
      {
        title: "Computer interface using eye tracking for handicapped people",
        authors: "EY Kim, SH Park",
        venue: "International Conference on Intelligent Data Engineering and Automated Learning",
		date:2006,
		type:"Conference",
        link: ""
      },
      {
        title: "Automatic video segmentation using genetic algorithms",
        authors: "EY Kim, SH Park",
        venue: "Pattern Recognition Letters 27 (11), 1252-1265",
		date:2006,
		type:"Journal",
        link: ""
      },
      {
        title: "Eye tracking using neural network and mean-shift",
        authors: "EY Kim, SK Kang",
        venue: "International Conference on Computational Science and Its Applications",
		date:2006,
		type:"Conference",
        link: ""
      },
      {
        title: "Film Line Scratch Detection using a Neural Network based Texture Classifier",
        authors: "KT Kim, EY Kim",
        venue: "Journal of the Institute of Electronics Engineers of Korea CI 43 (6), 26-33",
		date:2006,
		type:"Journal",
        link: ""
      },
      {
        title: "Eye Region Detection Method in Rotated Face using Global Orientation Information",
        authors: "Chang-Hyuk Jang, An-Jin Park, Kurata Takeshi, K Jain Anil, Se-Hyun Park, Eun-Yi Kim, Jong-Yeol Yang, Kee-Chul Jung",
        venue: "Journal of Korea Society of Industrial Information Systems",
		date:2006,
		type:"Journal",
        link: ""
      },
      {
        title: "Hidden Markov Model for Gesture Recognition",
        authors: "HS Park, EY Kim, HJ Kim",
        venue: "Journal of the Institute of Electronics Engineers of Korea CI 43 (1), 17-26",
		date:2006,
		type:"Journal",
        link: ""
      },
      {
        title: "Emotion-based textile indexing using colors, texture and patterns",
        authors: "S Kim, EY Kim, K Jeong, J Kim",
        venue: "Advances in Visual Computing: Second International Symposium, ISVC 2006 Lake Tahoe, NV, USA, November 6-8, 2006. Proceedings, Part II 2",
		date:2006,
		type:"Conference",
        link: ""
      },
      {
        title: "Real time hand tracking based on active contour model",
        authors: "JS Chang, EY Kim, KC Jung, HJ Kim",
        venue: "International Conference on Computational Science and Its Applications, 999-1006",
		date:2005,
		type:"Conference",
        link: ""
      },
      {
        title: "Eye mouse: mouse implementation using eye tracking",
        authors: "EY Kim, SK Kang, K Jung, HJ Kim",
        venue: "2005 Digest of Technical Papers. International Conference on Consumer Electronics, 2005. ICCE.",
		date:2005,
		type:"Conference",
        link: ""
      },
      {
        title: "Facial Boundary Detection using an Active Contour Model",
        authors: "EY Kim",
        venue: "Journal of the Institute of Electronics Engineers of Korea CI",
		date:2005,
		type:"Journal",
        link: ""
      },
      {
        title: "Genetic algorithms for video segmentation",
        authors: "EY Kim, K Jung",
        venue: "Pattern Recognition 38 (1), 59-73",
		date:2005,
		type:"Journal",
        link: ""
      },
      {
        title: "Film line scratch detection using neural network",
        authors: "SK Kang, EY Kim, K Jung, HJ Kim",
        venue: "Advances in Multimedia Information Processing-PCM 2004: 5th Pacific Rim Conference on Multimedia, Tokyo, Japan, November 30-December 3, 2004. Proceedings, Part II 5",
		date:2005,
		type:"Conference",
        link: ""
      },
      {
        title: "Object tracking using mean shift and active contours",
        authors: "JS Chang, EY Kim, KC Jung, HJ Kim",
        venue: "Innovations in Applied Artificial Intelligence: 18th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, IEA/AIE 2005, Bari, Italy, June 22-24, 2005. Proceedings 18",
		date:2005,
		type:"Conference",
        link: ""
      },
      {
        title: "Robot Competition Using Gesture Based Interface",
        authors: "HS Park, EY Kim, HJ Kim",
        venue: "Innovations in Applied Artificial Intelligence: 18th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, IEA/AIE 2005, Bari, Italy, June 22-24, 2005. Proceedings 18",
		date:2005,
		type:"Conference",
        link: ""
      },
      {
        title: "HMM-based gesture recognition for robot control",
        authors: "HS Park, EY Kim, SS Jang, SH Park, MH Park, HJ Kim",
        venue: "Pattern Recognition and Image Analysis: Second Iberian Conference, IbPRIA 2005, Estoril, Portugal, June 7-9, 2005, Proceedings, Part I 2",
		date:2005,
		type:"Conference",
        link: ""
      },
      {
        title: "Emotion-based textile indexing using colors and texture",
        authors: "EY Kim, S Kim, H Koo, K Jeong, J Kim",
        venue: "Fuzzy Systems and Knowledge Discovery: Second International Conference, FSKD 2005, Changsha, China, August 27-29, 2005, Proceedings, Part I 2",
		date:2005,
		type:"Conference",
        link: ""
      },
      {
        title: "An HMM based gesture recognition for perceptual user interface",
        authors: "HS Park, EY Kim, SS Jang, HJ Kim",
        venue: "Pacific-Rim Conference on Multimedia, 1027-1034",
		date:2004,
		type:"Conference",
        link: ""
      },
      {
        title: "Video segmentation using genetic algorithms with automatic parameter adaptation",
        authors: "EY Kim",
        venue: "Electronics Letters 40 (24), 1530-1531",
		date:2004,
		type:"Journal",
        link: ""
      },
      {
        title: "Recognition of human action for game system",
        authors: "HS Park, EY Kim, SS Jang, HJ Kim",
        venue: "International Conference on AI, Simulation, and Planning in High Autonomy Systems",
		date:2004,
		type:"Conference",
        link: ""
      },
      {
        title: "Object detection and removal using genetic algorithms",
        authors: "EY Kim, K Jung",
        venue: "Pacific Rim International Conference on Artificial Intelligence, 411-421",
		date:2004,
		type:"Conference",
        link: ""
      },
      {
        title: "Automatic text extraction for content-based image indexing",
        authors: "K Jung, EY Kim",
        venue: "Pacific-Asia Conference on Knowledge Discovery and Data Mining, 497-507",
		date:2004,
		type:"Conference",
        link: ""
      },
      {
        title: "Spatiotemporal parameter adaptation in genetic algorithm-based video segmentation",
        authors: "SK Kang, EY Kim, HJ Kim",
        venue: "PRICAI 2004: Trends in Artificial Intelligence: 8th Pacific Rim International Conference on Artificial Intelligence, Auckland, New Zealand, August 9-13, 2004. Proceedings 8",
		date:2004,
		type:"Conference",
        link: ""
      },
      {
        title: "Face detection with active contours using color information",
        authors: "JS Chang, EY Kim, HJ Kim",
        venue: "Conference on Technology Transfer, 334-343",
		date:2003,
		type:"Conference",
        link: ""
      },
      {
        title: "Motion segmentation using distributed genetic algorithms",
        authors: "EY Kim, SH Park",
        venue: "Iberian Conference on Pattern Recognition and Image Analysis, 378-385",
		date:2003,
		type:"Conference",
        link: ""
      },
      {
        title: "Automatic object-based video segmentation using distributed genetic algorithms",
        authors: "EY Kim, SH Park",
        venue: "International Conference on Computational Science and Its Applications, 312-321",
		date:2003,
		type:"Conference",
        link: ""
      },
      {
        title: "Automatic extraction of moving objects using distributed genetic algorithms",
        authors: "EY Kim, SH Park",
        venue: "International Conference on Intelligent Data Engineering and Automated Learning",
		date:2003,
		type:"Conference",
        link: ""
      },
      {
        title: "A Gesture-based interface for interactive computer games",
        authors: "HS Park, H Kang, KC Jung, EY Kim, MH Park, HJ Kim",
        venue: "Proceedings of the Korean Information Science Society Conference, 631-633",
		date:2003,
		type:"Conference",
        link: ""
      },
      {
        title: "A genetic algorithm with automatic parameter adaptation for video segmentation",
        authors: "EY Kim, SH Park",
        venue: "Computer Analysis of Images and Patterns: 10th International Conference, CAIP 2003, Groningen, The Netherlands, August 25-27, 2003. Proceedings 10",
		date:2003,
		type:"Conference",
        link: ""
      },
      {
        title: "Genetic algorithm-based video segmentation with adaptive population size",
        authors: "SH Park, EY Kim, BJ Cho",
        venue: "Pattern Recognition: 25th DAGM Symposium, Magdeburg, Germany, September 10-12, 2003. Proceedings 25",
		date:2003,
		type:"Conference",
        link: ""
      }
    ];

	const journals = pubData.filter(pub => pub.type === "Journal").sort((a, b) => b.date - a.date);

	const conferences = pubData.filter(pub => pub.type === "Conference").sort((a, b) => b.date - a.date);

    const pubList = document.getElementById('pubList');
	pubList.innerHTML = `
	  	<div style="font-size:1.2em;font-weight:600;color:#444;margin:2em 0 1em 0;">Conferences</div>
		<ul class="pub-list">
			${conferences.length === 0 ? `<li style="color:#aaa;">No conference papers yet.</li>` :
			conferences.map(pub => `
				<li class="pub-item">
				<div class="pub-title">${pub.title}${pub.link ? `<a href="${pub.link}" target="_blank" class="pub-link">[link]</a>` : ''}</div>
				<div class="pub-authors">${pub.authors}</div>
				<div class="pub-venue">${pub.venue} (${pub.date})</div>
				</li>
			`).join('')}
		</ul>
		<div style="font-size:1.2em;font-weight:600;color:#444;margin:2em 0 1em 0;">Journals</div>
		<ul class="pub-list">
			${journals.length === 0 ? `<li style="color:#aaa;">No journal papers yet.</li>` :
			journals.map(pub => `
				<li class="pub-item">
				<div class="pub-title">${pub.title}${pub.link ? `<a href="${pub.link}" target="_blank" class="pub-link">[link]</a>` : ''}</div>
				<div class="pub-authors">${pub.authors}</div>
				<div class="pub-venue">${pub.venue} (${pub.date})</div>
				</li>
			`).join('')}
		</ul>
		`;
    // pubList.innerHTML = '';
    // pubData.forEach(pub => {
    //   const li = document.createElement('li');
    //   li.className = 'pub-item';
    //   li.innerHTML = `
    //     <div class="pub-title">${pub.title}${pub.link ? `<a href="${pub.link}" target="_blank" class="pub-link">[link]</a>` : ''}</div>
    //     <div class="pub-authors">${pub.authors}</div>
    //     <div class="pub-venue">${pub.venue}</div>
    //   `;
    //   pubList.appendChild(li);
    // });
	// loadNews();

    // ----- News Data -----
    const newsData = [
      {
        id: 2,
        title: "Two Papers Accepted at INTERSPEECH 2025",
        content: "We are thrilled to announce that two papers from our lab have been accepted for presentation at INTERSPEECH 2025, one of the world’s premier conferences in speech and language processing.<br>These works reflect our lab’s continued efforts to advance emotion recognition and clinical speech analysis through cutting-edge AI methodologies.<br><br>📌 1. Contrastive Learning-based Syllable-Level Mispronunciation Detection and Diagnosis for Speech Audiometry (L Jin, D Min, JE Shin, EY Kim)<br><br>📌 2. MATER: Multi-level Acoustic and Textual Emotion Representation for Interpretable Speech Emotion Recognition (HJ Jon, L Jin, H Jung, H Kim, D Min, EY Kim)",
        date: "2025-05-21",
        image: ""
      },
      {
        id: 1,
        title: "🏆 1st Place at ICASSP 2023 ADReSS-M Challenge",
        content: 'We are proud to share that our team won 1st place in both tasks at the prestigious ADReSS-M Grand Challenge, held at ICASSP 2023 — the flagship conference for signal processing research.<br>The ADReSS-M (Alzheimer’s Dementia Recognition through Spontaneous Speech – Multilingual) Challenge focuses on an urgent and impactful goal: automatic detection of Alzheimer’s Dementia (AD) using only speech signals, with an emphasis on cross-lingual generalization. Participants were required to train models on English speech data and evaluate them on unseen Greek speech, pushing the boundary of robust multilingual dementia screening.<br><br>Our winning solution, titled:<br>🎓 "Consen: Complementary and Simultaneous Ensemble for Alzheimer’s Disease Detection and MMSE Score Prediction (L Jin, Y Oh, H Kim, H Jung, HJ Jon, JE Shin, EY Kim)"<br>demonstrated the highest performance in:<br>- Task 1: Binary classification of Alzheimer’s vs. control subjects<br>- Task 2: Regression of MMSE (Mini-Mental State Examination) cognitive scores<br><br>Our method leveraged a novel ensemble learning strategy that combines multiple acoustic perspectives while remaining robust to cross-language variability. The results validate the potential of acoustic-only, multilingual AD detection and highlight our commitment to AI for healthcare.',
        date: "2025-05-21",
        image: "news-images/icassp2023.jpg"
      }
    ];

    // Sort newsData by date descending before rendering
    const sortedNewsData = newsData.slice().sort((a, b) => new Date(b.date) - new Date(a.date));

    function loadNews() {
      const newsGrid = document.getElementById('newsGrid');
      newsGrid.innerHTML = '';
      sortedNewsData.forEach((item, idx) => {
        const newsCard = document.createElement('div');
        newsCard.className = 'news-card';
        let thumbHtml = '';
        if (item.image && item.image.trim() !== '') {
          thumbHtml = `<img src="${item.image}" alt="${item.title}" class="news-thumb">`;
        }
        newsCard.innerHTML = `
          ${thumbHtml}
          <div class="news-title">${item.title}</div>
          <div class="news-date">${item.date}</div>
          <div class="news-content-preview">${item.content.length > 100 ? item.content.slice(0, 100) + '...' : item.content}</div>
          <button class="news-readmore-btn" onclick="showNewsDetail(${idx})">Read More</button>
        `;
        newsGrid.appendChild(newsCard);
      });
    }

    // News modal logic
    window.showNewsDetail = function(index) {
      const item = sortedNewsData[index];
      if (!item) return;
      const modal = document.getElementById('newsModal');
      const modalContent = document.getElementById('newsModalContent');
      let imgHtml = '';
      if (item.image && item.image.trim() !== '') {
        imgHtml = `<img src="${item.image}" alt="${item.title}" class="news-modal-image">`;
      }
      modalContent.innerHTML = `
        <h2>${item.title}</h2>
        <div class="news-modal-date">${item.date}</div>
        ${imgHtml}
        <div class="news-modal-content">${item.content}</div>
        <button onclick="document.getElementById('newsModal').style.display='none'">Close</button>
      `;
      modal.style.display = 'block';
    }

    // Add CSS for .news-thumb, .news-card, .news-modal-image, etc. if not present
  </script>
</body>
</html>
